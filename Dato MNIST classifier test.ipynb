{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This trial license of GraphLab Create is assigned to trephine1@yahoo.com and will expire on October 12, 2015. Please contact trial@dato.com for licensing options or to request a free non-commercial license for personal or academic use.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-10050 - Server binary: /Users/mark/Galvanize/dato-env/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1442096508.log\n",
      "[INFO] GraphLab Server Version: 1.5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/dir_archive.ini to /var/tmp/graphlab-mark/10050/000000.ini\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/objects.bin to /var/tmp/graphlab-mark/10050/000001.bin\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.frame_idx to /var/tmp/graphlab-mark/10050/000002.frame_idx\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.sidx to /var/tmp/graphlab-mark/10050/000003.sidx\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/dir_archive.ini to /var/tmp/graphlab-mark/10050/000004.ini\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/objects.bin to /var/tmp/graphlab-mark/10050/000005.bin\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.frame_idx to /var/tmp/graphlab-mark/10050/000006.frame_idx\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.sidx to /var/tmp/graphlab-mark/10050/000007.sidx\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0000 to /var/tmp/graphlab-mark/10050/000008.0000\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0001 to /var/tmp/graphlab-mark/10050/000009.0001\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0002 to /var/tmp/graphlab-mark/10050/000010.0002\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0003 to /var/tmp/graphlab-mark/10050/000011.0003\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0004 to /var/tmp/graphlab-mark/10050/000012.0004\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0005 to /var/tmp/graphlab-mark/10050/000013.0005\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0006 to /var/tmp/graphlab-mark/10050/000014.0006\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/train/m_4558118e.0007 to /var/tmp/graphlab-mark/10050/000015.0007\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0000 to /var/tmp/graphlab-mark/10050/000016.0000\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0001 to /var/tmp/graphlab-mark/10050/000017.0001\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0002 to /var/tmp/graphlab-mark/10050/000018.0002\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0003 to /var/tmp/graphlab-mark/10050/000019.0003\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0004 to /var/tmp/graphlab-mark/10050/000020.0004\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0005 to /var/tmp/graphlab-mark/10050/000021.0005\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0006 to /var/tmp/graphlab-mark/10050/000022.0006\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/mnist/sframe/test/m_310c50b3.0007 to /var/tmp/graphlab-mark/10050/000023.0007\n",
      "Layers of the network \n",
      "--------------------------------------------------------\n",
      "layer[0]: ConvolutionLayer\n",
      "  init_random = xavier\n",
      "  padding = 1\n",
      "  stride = 2\n",
      "  num_channels = 32\n",
      "  num_groups = 1\n",
      "  kernel_size = 3\n",
      "layer[1]: MaxPoolingLayer\n",
      "  padding = 0\n",
      "  stride = 2\n",
      "  kernel_size = 3\n",
      "layer[2]: FlattenLayer\n",
      "layer[3]: DropoutLayer\n",
      "  threshold = 0.5\n",
      "layer[4]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 100\n",
      "layer[5]: SigmoidLayer\n",
      "layer[6]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 10\n",
      "layer[7]: SoftmaxLayer\n",
      "Parameters of the network \n",
      "--------------------------------------------------------\n",
      "{'init_random': 'gaussian', 'learning_rate': 0.1, 'input_shape': '1,28,28', 'batch_size': 100, 'divideby': 255, 'l2_regularization': 0.0, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "\n",
    "# Load the MNIST data (from an S3 bucket)\n",
    "data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
    "test_data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/test')\n",
    "\n",
    "# Random split the training-data\n",
    "training_data, validation_data = data.random_split(0.8)\n",
    "\n",
    "# Make sure all images are of the same size (Required by Neuralnets)\n",
    "for sf in [training_data, validation_data, test_data]:\n",
    "  sf['image'] = gl.image_analysis.resize(sf['image'], 28, 28, 1)\n",
    "\n",
    "net = gl.deeplearning.get_builtin_neuralnet('mnist')\n",
    "\n",
    "print \"Layers of the network \"\n",
    "print \"--------------------------------------------------------\"\n",
    "print net.layers\n",
    "\n",
    "print \"Parameters of the network \"\n",
    "print \"--------------------------------------------------------\"\n",
    "print net.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using network:\n",
      "\n",
      "### network layers ###\n",
      "layer[0]: ConvolutionLayer\n",
      "  init_random = xavier\n",
      "  padding = 1\n",
      "  stride = 2\n",
      "  num_channels = 32\n",
      "  num_groups = 1\n",
      "  kernel_size = 3\n",
      "layer[1]: MaxPoolingLayer\n",
      "  padding = 0\n",
      "  stride = 2\n",
      "  kernel_size = 3\n",
      "layer[2]: FlattenLayer\n",
      "layer[3]: DropoutLayer\n",
      "  threshold = 0.5\n",
      "layer[4]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 100\n",
      "layer[5]: SigmoidLayer\n",
      "layer[6]: FullConnectionLayer\n",
      "  init_sigma = 0.01\n",
      "  init_random = gaussian\n",
      "  init_bias = 0\n",
      "  num_hidden_units = 10\n",
      "layer[7]: SoftmaxLayer\n",
      "### end network layers ###\n",
      "\n",
      "### network parameters ###\n",
      "init_random = gaussian\n",
      "learning_rate = 0.1\n",
      "input_shape = 1,28,28\n",
      "batch_size = 100\n",
      "divideby = 255\n",
      "l2_regularization = 0.0\n",
      "metric = accuracy,recall@2\n",
      "momentum = 0.9\n",
      "### end network parameters ###\n",
      "\n",
      "PROGRESS: Computing mean image...\n",
      "PROGRESS: Done computing mean image.\n",
      "PROGRESS: Creating neuralnet using cpu\n",
      "PROGRESS: Training with batch size = 100\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+-------------------+---------------------+-----------------+\n",
      "PROGRESS: | Iteration | Examples | Elapsed Time | Training-accuracy | Validation-accuracy | Training-recall@2 | Validation-recall@2 | Examples/second |\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+-------------------+---------------------+-----------------+\n",
      "PROGRESS: | 1         | 10300    | 10.036544    | 0.347961          |                     | 0.490777          |                     | 1026.250610     |\n",
      "PROGRESS: | 1         | 20600    | 20.051155    | 0.593350          |                     | 0.714369          |                     | 1028.496704     |\n",
      "PROGRESS: | 1         | 30900    | 30.117127    | 0.701521          |                     | 0.799903          |                     | 1023.249390     |\n",
      "PROGRESS: | 1         | 41100    | 40.137975    | 0.758467          |                     | 0.843796          |                     | 1017.877991     |\n",
      "PROGRESS: | 1         | 48100    | 51.531952    | 0.784511          | 0.958845            | 0.863721          | 0.987979            | 614.359497      |\n",
      "PROGRESS: | 2         | 10200    | 61.557225    | 0.947647          |                     | 0.982059          |                     | 1017.446045     |\n",
      "PROGRESS: | 2         | 20300    | 71.591063    | 0.948818          |                     | 0.982562          |                     | 1006.593933     |\n",
      "PROGRESS: | 2         | 30500    | 81.661896    | 0.950984          |                     | 0.984361          |                     | 1012.825745     |\n",
      "PROGRESS: | 2         | 40700    | 91.702061    | 0.952654          |                     | 0.985602          |                     | 1015.919678     |\n",
      "PROGRESS: | 2         | 48100    | 103.514256   | 0.953576          | 0.975207            | 0.985738          | 0.993322            | 626.471008      |\n",
      "PROGRESS: | 3         | 10400    | 113.584331   | 0.960481          |                     | 0.988462          |                     | 1032.787842     |\n",
      "PROGRESS: | 3         | 20800    | 123.668764   | 0.962260          |                     | 0.989038          |                     | 1031.292480     |\n",
      "PROGRESS: | 3         | 31100    | 133.699763   | 0.964180          |                     | 0.989228          |                     | 1026.817017     |\n",
      "PROGRESS: | 3         | 41400    | 143.739056   | 0.963913          |                     | 0.989541          |                     | 1025.968628     |\n",
      "PROGRESS: | 3         | 48100    | 154.764885   | 0.964241          | 0.978379            | 0.989813          | 0.994240            | 607.663879      |\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+-------------------+---------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "model = gl.neuralnet_classifier.create(training_data, target='label',\n",
    "                                         network = net,\n",
    "                                         validation_set=validation_data,\n",
    "                                         metric=['accuracy', 'recall@2'],\n",
    "                                         max_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+\n",
      "| row_id | class |     score      |\n",
      "+--------+-------+----------------+\n",
      "|   0    |   0   | 0.998517096043 |\n",
      "|   1    |   0   | 0.99977439642  |\n",
      "|   2    |   0   | 0.999371349812 |\n",
      "|   3    |   0   | 0.994148373604 |\n",
      "|   4    |   0   | 0.999643802643 |\n",
      "|   5    |   0   | 0.998987734318 |\n",
      "|   6    |   0   | 0.997004210949 |\n",
      "|   7    |   0   | 0.999610006809 |\n",
      "|   8    |   0   |  0.9966609478  |\n",
      "|   9    |   0   | 0.999795615673 |\n",
      "+--------+-------+----------------+\n",
      "[10000 rows x 3 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.classify(test_data)\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------------+\n",
      "| row_id | class |       score       |\n",
      "+--------+-------+-------------------+\n",
      "|   0    |   0   |   0.998517096043  |\n",
      "|   0    |   6   | 0.000474064901937 |\n",
      "|   1    |   0   |   0.99977439642   |\n",
      "|   1    |   2   | 0.000115993869258 |\n",
      "|   2    |   0   |   0.999371349812  |\n",
      "|   2    |   2   | 0.000200508176931 |\n",
      "|   3    |   0   |   0.994148373604  |\n",
      "|   3    |   8   |  0.00261444156058 |\n",
      "|   4    |   0   |   0.999643802643  |\n",
      "|   4    |   2   | 0.000103457256046 |\n",
      "+--------+-------+-------------------+\n",
      "[20000 rows x 3 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "pred_top2 = model.predict_topk(test_data, k=2)\n",
    "print pred_top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy         : 0.979499995708\n",
      "Confusion Matrix : \n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      5       |        5        |  869  |\n",
      "|      0       |        5        |   3   |\n",
      "|      6       |        5        |   7   |\n",
      "|      8       |        5        |   2   |\n",
      "|      1       |        5        |   1   |\n",
      "|      9       |        5        |   2   |\n",
      "|      2       |        2        |  1011 |\n",
      "|      7       |        2        |   11  |\n",
      "|      3       |        2        |   1   |\n",
      "|      4       |        2        |   1   |\n",
      "+--------------+-----------------+-------+\n",
      "[64 rows x 3 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data)\n",
    "print \"Accuracy         : %s\" % result['accuracy']\n",
    "print \"Confusion Matrix : \\n%s\" % result['confusion_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment: effing impressive. Training/optimizing an Octave-based model to do barely a hair better took me weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
