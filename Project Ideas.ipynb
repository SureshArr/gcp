{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Identify Craigslist Scammers\n",
    "\n",
    "###Especially for short-term and vacation rentals, scammers are abundant. Identify likely candidates.\n",
    "\n",
    "####Requirements:\n",
    "\n",
    "* Scraping a large number of Craigslist sublet and vacation rental ads.\n",
    "* (Almost certainly) identifying a large number of scam ads for a training set.\n",
    "* Most reliable method for obtaining training set: automated e-mails, identifying scammers as those who disappear once mention of \"verifiable transfer of money & key phrase\" is used.\n",
    "* NLP, classifier and/or similarity methods.\n",
    "\n",
    "####Pros:\n",
    "\n",
    "* Very nice to have.\n",
    "* Could be used to identify interesting aspects of scams, frequently-used e-mails, etc.\n",
    "* Success may attract attention (good and bad).\n",
    "* For some scams, could identify as such by extracting address information and searching web / Trulia for alternate listing info. If listed as for sale, probably a scam. If listed for a higher rate on property management site, probably a scam.\n",
    "\n",
    "####Cons:\n",
    "\n",
    "* To identify 100s/1000s of classified scams, would need to ask (using automation) 1000s of *legitimate* ad posters to respond. That amounts to asking for 100s of hours of free effort.\n",
    "* To distinguish between ads no longer active and actual scams, would need a round of back and forth before the question about verifiable transactions. This might require significant NLP. (But maybe not.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ben comments\n",
    "\n",
    "* LinkedIn network connecting to Craigslist.\n",
    "* Narrow the predictions. Predict those which might be flagged.\n",
    "\n",
    "* Figure out what may be trending \n",
    "\n",
    "* BART historical data for predicting delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Crime, there's so much crime\n",
    "\n",
    "###Many cities now have open data initiatives, providing policing and crime statistics in downloadable files. These cases are linked to location, and in some instances, to census tracts. The idea would be to use the data to forecast likelihood of crimes by census tract, time of year, other thangs(?)\n",
    "\n",
    "####Requirements:\n",
    "\n",
    "* Not so many, although visualizations would be essential.\n",
    "\n",
    "####Pros:\n",
    "\n",
    "* Might be fairly useful, occasionally interesting\n",
    "* \n",
    "\n",
    "####Cons:\n",
    "\n",
    "* Not a big step beyond reporting the facts\n",
    "* Crimewatch/Crimeview already present crime stats as map visualizations for many locations. How significant is the value-add?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neighbor View Contrast\n",
    "\n",
    "###Examines geolocated blogs to learn what people in adjacent areas are saying about a hot topic.\n",
    "\n",
    "####Requirements:\n",
    "\n",
    "* Scraping a large number of blogs\n",
    "* NLP, 'sentiment analysis', topic modeling, focused on key phrase (search terms)\n",
    "* Some form of visualization, including heat maps.\n",
    "\n",
    "####Pros:\n",
    "\n",
    "* Could be very interesting to see ways in which viewpoints diverge, even where geographical distances may be small.\n",
    "* Useful for exploring dynamics of hot topics\n",
    "\n",
    "####Cons:\n",
    "\n",
    "* Geolocation a likely barrier. Alternative would be twitter, for the fraction of users with GPS enabled.\n",
    "* A second alternative would be to do topic analysis of blogs to identify views by some other classifier. But how to keep this mutually consistent, rather than saying those matching topic A are like topic A?\n",
    "* If reliant on twitter, sentiment analysis 300 $\\times$ harder.\n",
    "* Selection bias: blogs are written by people who care to learn blogging software, write in complete sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Piss Me Off, Please\n",
    "\n",
    "###This would be a news recommender that ingests many articles discussing a topic (thank you Google News aggregator) and would find and recommend $n$ that represent divergent takes on the subject.\n",
    "\n",
    "####Requirements:\n",
    "\n",
    "* scraping and parsing news aggregators (or at least Google)\n",
    "* For each topic listed, scrape URLs, and then articles, listed\n",
    "* For each topic, run topic modelling on those articles.\n",
    "* $\\longrightarrow$ somehow would need to decide what to present. One from each topic? Is there a means for ordering them as 'left', 'right', 'crazy?'\n",
    "* Might work to represent articles as being relatively 'favorable' or 'negative' in presentation of topic, or to simply present 3 'most-dissimilar' articles?\n",
    "\n",
    "####Pros:\n",
    "\n",
    "* Ideally, would help readers avoid confirmation biases\n",
    "* Showcase NLP\n",
    "\n",
    "####Cons:\n",
    "\n",
    "* Sentiment analysis is too crude. Eg., an article about unhappy refuges would score negative on basic sentiment analysis, even if the article favorably portrayed efforts to mitigate the problems.\n",
    "* Similarly, 'pro-life' and 'pro-choice' might yield similar tf-idf values in a document, but how applied tells much.\n",
    "* Problems with paywalls!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Ideally, I would ...\n",
    "\n",
    "* Project would demonstrate utility (not academic)\n",
    "* Apply some form of anomaly detection\n",
    "* Apply deep learning\n",
    "* Apply to something relevant to either health or education, which would be my first target 'industries' for future employment.\n",
    "\n",
    "###Caveats:\n",
    "\n",
    "* Need a project that I will *get done*, and which *will work*\n",
    "* Some of my 'ideal goals' above are contradictory (so I will pick and choose between them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
