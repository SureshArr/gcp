{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are numerous decisions for me to make (very quickly):\n",
    "\n",
    "* How to present results of classifier so that they do not bias viewer's interpretation of greyscale images. (If I use color, viewer is likely as not to be tricked by the colors into believing there are differences where labeled, even if not merited by the underlying data.\n",
    "* Should I attempt iForest anomaly detection on images? **Yes!**\n",
    "  * Advantage: (there exists code) [there exists code](http://stackoverflow.com/questions/30080491/isolation-forest-algorithm-in-python \"code provided by user on stackoverflow\")\n",
    "  * Disadvantages: author claims that it is slow, it is not well tested. *Seems to work.*\n",
    "  * That same reference points to sklearn github pull-request for [a model of increasing maturity](https://github.com/scikit-learn/scikit-learn/pull/4163 \"not yet ready for sklearn\"), but not yet fully working and not super-well-tested. Another month or two?\n",
    "  * To impliment iForest, would need to extract feature weights from trained model. Can I do this with Dato's imagenet classifier? **Yes! However, there are devils in the details to be worked out.**\n",
    "  \n",
    "### Regarding presentation:\n",
    "  \n",
    "  * For minimum viable product:\n",
    "    * Use [Flask-Uploads](https://pythonhosted.org/Flask-Uploads/) to allow a user to upload a directory filled with images.\n",
    "    * Apply iForest and rank by anomaly score\n",
    "    * Present a table with columns [256 x 256 images, file names, anomaly score], ranked by anomaly score.\n",
    "\n",
    "  * If can't work out NN features, do minimum minimum viable product using iForest on pixel values.\n",
    "  \n",
    "### Things to implement:\n",
    "\n",
    "  * Make sure that can work with color photos as well as grayscale. Should app to a detect on each file and convert to that which is most consistent with others in directory?\n",
    "  * Would be great to add audio, converting to FFT, clipping or repeating to a nominal length.\n",
    "  * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from code import iForest as isof\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try iForest using real image data (raw pixels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngCt: 2064\n",
      "/home/wilber/work/Galvanize/gcp-data/iForest\n",
      "0\thdll020+0300+0126.png\t<type 'numpy.ndarray'>\n",
      "100\twshdll020+0740+0086.png\t<type 'numpy.ndarray'>\n",
      "200\tldlm020+0620+0086.png\t<type 'numpy.ndarray'>\n",
      "300\thdmm000+0460+0166.png\t<type 'numpy.ndarray'>\n",
      "400\tnthdmm020+0340+0166.png\t<type 'numpy.ndarray'>\n",
      "500\twshdll000+1500+0126.png\t<type 'numpy.ndarray'>\n",
      "600\thdll020+0220+0086.png\t<type 'numpy.ndarray'>\n",
      "700\twshdmm020+1180+0166.png\t<type 'numpy.ndarray'>\n",
      "800\tntldlm020+0860+0166.png\t<type 'numpy.ndarray'>\n",
      "900\tldlm020+0780+0166.png\t<type 'numpy.ndarray'>\n",
      "1000\tldlm020+1620+1086.png\t<type 'numpy.ndarray'>\n",
      "1100\tldlm000+1060+0166.png\t<type 'numpy.ndarray'>\n",
      "1200\thdlr020+0300+0166.png\t<type 'numpy.ndarray'>\n",
      "1300\tnthdlr020+0500+0166.png\t<type 'numpy.ndarray'>\n",
      "1400\tntldlm020+1140+1046.png\t<type 'numpy.ndarray'>\n",
      "1500\twshdlr000+0540+0166.png\t<type 'numpy.ndarray'>\n",
      "1600\thdll020+0460+0126.png\t<type 'numpy.ndarray'>\n",
      "1700\twsldlm000+1460+0126.png\t<type 'numpy.ndarray'>\n",
      "1800\thdlr020+1300+1006.png\t<type 'numpy.ndarray'>\n",
      "1900\tntldlm000+0620+0166.png\t<type 'numpy.ndarray'>\n",
      "2000\tldlm000+1100+0166.png\t<type 'numpy.ndarray'>\n",
      "(2064, 10000)\n",
      "[[  56.   75.   84.   79.   76.   74.   74.   80.   76.   77.   78.   69.\n",
      "    79.   76.   89.   74.   78.   77.   69.   99.]\n",
      " [  40.   40.   37.   35.   34.   35.   37.   38.   36.   34.   35.   37.\n",
      "    37.   37.   38.   38.   40.   42.   44.   49.]\n",
      " [  90.  120.  122.   84.   66.   70.   83.   98.   98.   95.   98.   92.\n",
      "    97.   97.   93.   94.   94.   87.   70.   59.]\n",
      " [  56.   55.   60.   62.   60.   56.   53.   54.   55.   56.   56.   56.\n",
      "    55.   55.   56.   58.   60.   61.   62.   64.]\n",
      " [  52.   55.   55.   51.   48.   46.   52.   58.   58.   55.   57.   63.\n",
      "    56.   50.   49.   49.   50.   51.   53.   51.]\n",
      " [  76.   82.   84.   87.  100.   99.   86.   65.   63.   73.   67.   65.\n",
      "    74.   89.   84.   70.   76.   86.   72.   72.]\n",
      " [  46.   45.   45.   45.   44.   44.   44.   43.   45.   44.   44.   46.\n",
      "    46.   43.   42.   43.   44.   44.   44.   45.]\n",
      " [  25.   33.   37.   56.   73.   98.  107.  114.  109.  106.   95.   83.\n",
      "    93.  108.  109.   94.   66.   80.  108.  116.]\n",
      " [  72.   70.   64.   63.   66.   68.   68.   70.   77.   85.   83.   77.\n",
      "    82.   87.   84.   73.   62.   56.   75.   94.]\n",
      " [  71.   73.   75.   82.   96.  104.   96.   82.   81.   74.   77.   93.\n",
      "   102.   99.   96.   97.   97.   95.  103.  101.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hdll020+0300+0126.png',\n",
       " 'wsldlm000+0820+0166.png',\n",
       " 'nthdmm000+1020+1006.png',\n",
       " 'ntldlm000+1540+0166.png',\n",
       " 'ntldlm000+1020+0166.png',\n",
       " 'nthdlr020+0260+0046.png',\n",
       " 'ntldlm020+1020+1086.png',\n",
       " 'nthdll020+1340+1086.png',\n",
       " 'wshdll020+0500+0086.png',\n",
       " 'wshdlr000+1380+0126.png']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "WORK_DIR = '/home/wilber/work/Galvanize/gcp-data/iForest/'\n",
    "pngCt = len(glob.glob1(WORK_DIR,\"*.png\"))\n",
    "print \"pngCt: {0}\".format(pngCt)\n",
    "%cd /home/wilber/work/Galvanize/gcp-data/iForest/\n",
    "Xraw = np.full((pngCt, 10000), np.nan)\n",
    "names = [\"\"]*pngCt\n",
    "for i, file in enumerate(os.listdir(WORK_DIR)):\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    if i % 100 == 0:\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, file, type(img))\n",
    "    Xraw[i,:] = img.flatten()\n",
    "    names[i] = file\n",
    "print Xraw.shape\n",
    "print Xraw[:10, :20]\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/wilber/work/Galvanize/gcp'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level features from Dato's ImageNet classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Unsupported image format. Supported formats are JPG and PNG\t file: /home/wilber/work/Galvanize/gcp-data/iForest/mean/mean_array/m_3fe07a27219448.sidx\n",
      "PROGRESS: Unsupported image format. Supported formats are JPG and PNG\t file: /home/wilber/work/Galvanize/gcp-data/iForest/mean/mean_array/dir_archive.ini\n",
      "PROGRESS: Unsupported image format. Supported formats are JPG and PNG\t file: /home/wilber/work/Galvanize/gcp-data/iForest/mean/mean_array/m_3fe07a27219448.0000\n",
      "PROGRESS: Unsupported image format. Supported formats are JPG and PNG\t file: /home/wilber/work/Galvanize/gcp-data/iForest/mean/mean_array/objects.bin\n",
      "Help on DeepFeatureExtractor in module graphlab.toolkits.feature_engineering._deep_feature_extractor object:\n",
      "\n",
      "class DeepFeatureExtractor(graphlab.toolkits.feature_engineering._feature_engineering.TransformerBase)\n",
      " |  Takes an input dataset, propagates each example through the network,\n",
      " |  and returns an SArray of dense feature vectors, each of which is the\n",
      " |  concatenation of all the hidden unit values at layer[layer_id]. These\n",
      " |  feature vectors can be used as input to train another classifier such as a\n",
      " |  :py:class:`~graphlab.logistic_classifier.LogisticClassifier`,\n",
      " |  an :py:class:`~graphlab.svm_classifier.SVMClassifier`, another\n",
      " |  :py:class:`~graphlab.neuralnet_classifier.NeuralNetClassifier`,\n",
      " |   or a :py:class:`~graphlab.boosted_trees_classifier.BoostedTreesClassifier`.\n",
      " |  \n",
      " |  A pre-trained model for ImageNet, as described by Alex Krizhevsky et. al.\n",
      " |  is avaliable for use at\n",
      " |  \"http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45\".\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature : str\n",
      " |      Name of feature column to be transformed.\n",
      " |  \n",
      " |  model: 'auto' | A model of type NeuralNetClassifier\n",
      " |      The model to extract features from. By default ('auto'), we chose an\n",
      " |      appropriate model from our batch of pre-trained models.\n",
      " |  \n",
      " |  output_column_name: str, optional\n",
      " |      The output column name of the transform. If specified, it a new column\n",
      " |      name with the specified column name is added to the input SFrame. Otherwise,\n",
      " |      the term 'deep_features' is appended to the original column name. If\n",
      " |      the column name already exists, then the output column name is appended\n",
      " |      with a number to make sure it is unique.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  graphlab.toolkits.feature_engineering.create\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  - Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"Imagenet\n",
      " |  classification with deep convolutional neural networks.\" Advances in\n",
      " |  neural information processing systems. 2012.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DeepFeatureExtractor\n",
      " |      graphlab.toolkits.feature_engineering._feature_engineering.TransformerBase\n",
      " |      graphlab.toolkits._model.CustomModel\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature, model='auto', output_column_name=None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  fit(self, data)\n",
      " |      Fits a transformer using the SFrame `data`. The `fit` phase does not\n",
      " |      train a deep learning model, it only checks that the trained model\n",
      " |      is comptable with the data provided. If the `auto` model is chosen, then\n",
      " |      the fit phase choses the right model to extract features from.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : SFrame\n",
      " |          The data used to fit the transformer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self (A fitted object)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      transform, fit_transform\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Create data.\n",
      " |      >>> import graphlab as gl\n",
      " |      \n",
      " |      # Import data from MNIST\n",
      " |      >>> data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      \n",
      " |      # Create a DeepFeatureExtractorObject\n",
      " |      >>> extractor = gl.feature_engineering.DeepFeatureExtractor(\n",
      " |                                                  features = 'image')\n",
      " |      \n",
      " |      # Fit the encoder for a given dataset.\n",
      " |      >>> extractor = extractor.fit(data)\n",
      " |      \n",
      " |      # Return the model used for the deep feature extraction.\n",
      " |      >>> extractor['model']\n",
      " |  \n",
      " |  fit_transform(self, data)\n",
      " |      First fit a transformer using the SFrame `data` and then return a transformed\n",
      " |      version of `data`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : SFrame\n",
      " |          The data used to fit the transformer. The same data is then also\n",
      " |          transformed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Transformed SFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fit fit_transform\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      - Fit transform modifies self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: python\n",
      " |      \n",
      " |      >>> import graphlab as gl\n",
      " |      \n",
      " |      # Import data from MNIST\n",
      " |      >>> data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      \n",
      " |      # Create a DeepFeatureExtractorObject\n",
      " |      >>> extractor = gl.feature_engineering.DeepFeatureExtractor(\n",
      " |                                                  features = 'image')\n",
      " |      \n",
      " |      # Fit the extractor for a given dataset.\n",
      " |      >>> extractor = extractor.fit(data)\n",
      " |      \n",
      " |      # Fit the extractor for a given dataset.\n",
      " |      >>> data_with_features = extractor.transform(data)\n",
      " |  \n",
      " |  get(self, field)\n",
      " |      Return the value contained in the model's ``field``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      field : string\n",
      " |          Name of the field to be retrieved.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out\n",
      " |          Value of the requested field.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      list_fields\n",
      " |  \n",
      " |  get_current_options(self)\n",
      " |      Return a dictionary with the options used to define and train the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : dict\n",
      " |          Dictionary with options used to define and train the model.\n",
      " |      \n",
      " |      Examples\n",
      " |      -------\n",
      " |      >>> options = m.get_current_options()\n",
      " |  \n",
      " |  list_fields(self)\n",
      " |      List of fields stored in the model. Each of these fields can be queried\n",
      " |      using the ``get(field)`` function or ``m[field]``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : list[str]\n",
      " |          A list of fields that can be queried using the ``get`` method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> fields = m.list_fields()\n",
      " |  \n",
      " |  transform(self, data)\n",
      " |      Transform the SFrame `data` using a fitted model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : SFrame\n",
      " |          The data  to be transformed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A transformed SFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out: SFrame\n",
      " |          A transformed SFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fit, fit_transform\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import graphlab as gl\n",
      " |      \n",
      " |      # Import data from MNIST\n",
      " |      >>> data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      \n",
      " |      # Create a DeepFeatureExtractorObject\n",
      " |      >>> extractor = gl.feature_engineering.DeepFeatureExtractor(\n",
      " |                                                  features = 'image')\n",
      " |      \n",
      " |      # Fit the extractor for a given dataset.\n",
      " |      >>> data = extractor.fit_transform(data)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  get_default_options = _get_default_options(output_type='sframe')\n",
      " |      Return information about the default options.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      output_type : str, optional\n",
      " |      \n",
      " |          The output can be of the following types.\n",
      " |      \n",
      " |          - `sframe`: A table description each option used in the model.\n",
      " |          - `json`: A list of option dictionaries.\n",
      " |      \n",
      " |          | Each dictionary/row in the JSON/SFrame object describes the\n",
      " |            following parameters of the given model.\n",
      " |      \n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |          |      Name        |                  Description                          |\n",
      " |          +==================+=======================================================+\n",
      " |          | name             | Name of the option used in the model.                 |\n",
      " |          +------------------+---------+---------------------------------------------+\n",
      " |          | description      | A detailed description of the option used.            |\n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |          | type             | Option type.                                          |\n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |          | default_value    | The default value for the option.                     |\n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |          | possible_values  | List of acceptable values (CATEGORICAL only)          |\n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |          | lower_bound      | Smallest acceptable value for this option (REAL only) |\n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |          | upper_bound      | Largest acceptable value for this option (REAL only)  |\n",
      " |          +------------------+-------------------------------------------------------+\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : JSON/SFrame\n",
      " |          Each row in the output SFrames correspond to a parameter, and includes\n",
      " |          columns for default values, lower and upper bounds, description ,and\n",
      " |          type.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._model.CustomModel:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  save(self, location)\n",
      " |      Save the model. The model is saved as a directory which can then be\n",
      " |      loaded using the :py:func:`~graphlab.load_model` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      location : string\n",
      " |          Target destination for the model. Can be a local path or remote URL.\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      graphlab.load_model\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      >>> model.save('my_model_file')\n",
      " |      >>> loaded_model = gl.load_model('my_model_file')\n",
      " |  \n",
      " |  show(self, view=None, model_type='base')\n",
      " |      show(view=None)\n",
      " |      Visualize with GraphLab Canvas :mod:`~graphlab.canvas`.\n",
      " |      This function starts Canvas if it is not already running.\n",
      " |      If the Model has already been plotted, this function will update the plot.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      view : str, optional\n",
      " |          The name of the Model view to show. Can be one of:\n",
      " |      \n",
      " |          - 'Summary': The summary description of a Model.\n",
      " |      \n",
      " |          - 'Evaluation': A visual representation of the evaluation results for\n",
      " |              a Model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      view : graphlab.canvas.view.View\n",
      " |          An object representing the GraphLab Canvas view\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canvas\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Suppose 'm' is a Model, we can view it in GraphLab Canvas using:\n",
      " |      \n",
      " |      >>> m.show()\n",
      " |  \n",
      " |  summary(self, output=None)\n",
      " |      Print a summary of the model.\n",
      " |      The summary includes a description of training\n",
      " |      data, options, hyper-parameters, and statistics measured during model\n",
      " |      creation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> m.summary()\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      output : string, None\n",
      " |          The type of summary to return.\n",
      " |          None or 'stdout' : prints directly to stdout\n",
      " |          'str' : string of summary\n",
      " |          'dict' : a dict with 'sections' and 'section_titles' ordered lists\n",
      " |                      The entries in the 'sections' list are tuples of the form ('label', 'value')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from graphlab.toolkits._model.CustomModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "0.572710990906\n",
      "\n",
      "\n",
      "0.00276589393616\n",
      "\n",
      "\n",
      "0.000155925750732\n",
      "\n",
      "\n",
      "783.39815712 , total time:  783.97378993\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "WORKING_DIR = '/home/wilber/work/Galvanize/gcp-data/iForest/'\n",
    "data = gl.image_analysis.load_images(WORKING_DIR, \\\n",
    "                                     random_order=True)\n",
    "data['image'] = gl.image_analysis.resize(data['image'], 256, 256)\n",
    "\n",
    "# Import data from MNIST\n",
    "#data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
    "\n",
    "# Create a DeepFeatureExtractorObject\n",
    "\n",
    "start = time.time()\n",
    "extractor = gl.feature_engineering.DeepFeatureExtractor(feature = 'image')\n",
    "print help(extractor)\n",
    "# Fit the encoder for a given dataset.\n",
    "time1 = time.time()\n",
    "print \"\\n\\n\", time1 - start\n",
    "extractor = extractor.fit(data)\n",
    "time2 = time.time()\n",
    "print \"\\n\\n\", time2 - time1\n",
    "\n",
    "# Return the model used for the deep feature extraction.\n",
    "extracted_model = extractor['model']\n",
    "time3 = time.time()\n",
    "print \"\\n\\n\", time3 - time2\n",
    "\n",
    "# Extract features.\n",
    "features_sf = extractor.transform(data)\n",
    "features_sf.head()\n",
    "time4 = time.time()\n",
    "print \"\\n\\n\", time4 - time3, \", total time: \", time4 - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature = features_sf.head['deep_features_image']\n",
    "features_sf.num_rows(), features_sf.num_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class               : NeuralNetClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Examples            : 1281166\n",
       "Features            : 1\n",
       "Target column       : label\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Training accuracy   : 0.625\n",
       "Validation accuracy : None\n",
       "Training recall@5   : 0.8512\n",
       "Validation recall@5 : None\n",
       "Training time (sec) : 288884.0298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Class               : NeuralNetClassifier\n",
      "\n",
      "Schema\n",
      "------\n",
      "Examples            : 1281166\n",
      "Features            : 1\n",
      "Target column       : label\n",
      "\n",
      "Training Summary\n",
      "----------------\n",
      "Training accuracy   : 0.625\n",
      "Validation accuracy : None\n",
      "Training recall@5   : 0.8512\n",
      "Validation recall@5 : None\n",
      "Training time (sec) : 288884.0298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opts_dict = extractor.get_current_options()\n",
    "for key, value in opts_dict.iteritems():\n",
    "    print key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class               : DeepFeatureExtractor\\n\\nModel fields\\n------------\\nFeature(s)          : image\\nOutput Column Name  : deep_features_image\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['path', 'image', 'deep_features_image']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sf.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 4096)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(features_sf['deep_features_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(features_sf['deep_features_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.72930121,  0.        , ...,  0.        ,\n",
       "         0.94428813,  0.        ],\n",
       "       [ 0.        ,  1.59159303,  0.        , ...,  0.        ,\n",
       "         0.6683253 ,  0.60917962],\n",
       "       [ 1.48337448,  0.        ,  0.65555978, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  2.86736774,  0.        , ...,  0.        ,\n",
       "         1.75487328,  0.        ],\n",
       "       [ 1.57783175,  1.64519286,  0.        , ...,  0.        ,\n",
       "         1.5495981 ,  0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369.748157024\n"
     ]
    }
   ],
   "source": [
    "model = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "model.fit(X)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\twsldlm000+1340+0126.png\t0.615487381279\n",
      "2\tnthdll000+0820+0166.png\t0.590250183857\n",
      "3\thdlr020+0980+0166.png\t0.566325593441\n",
      "4\tnthdlr020+1100+1046.png\t0.549250004206\n",
      "5\thdmm020+1020+0166.png\t0.488050215793\n",
      "6\tldlm020+0300+0166.png\t0.474663087353\n",
      "7\twshdmm020+0900+0086.png\t0.459938195728\n",
      "8\tnthdll020+1180+1126.png\t0.455982553333\n",
      "9\twshdll020+0420+0086.png\t0.452169702796\n",
      "10\thdmm020+0340+0126.png\t0.451372111184\n",
      "11\tnthdmm020+0820+1006.png\t0.448498633964\n",
      "12\twshdmm020+0620+0126.png\t0.446066758839\n",
      "13\thdlr020+0540+0046.png\t0.441880783274\n",
      "14\tntldlm000+0300+1006.png\t0.440740666117\n",
      "15\thdll000+0460+0166.png\t0.440144821711\n",
      "\n",
      "\n",
      "478\tfig01.png\t0.322530355659\n",
      "737\tfig03.png\t0.301604729085\n",
      "1165\tfig00.png\t0.275853525065\n",
      "1850\tfig02.png\t0.234054963318\n"
     ]
    }
   ],
   "source": [
    "anom_scores = model.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different layers from pre-trained model:\n",
    "\n",
    "#### Layer 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601696014404\n",
      "803.75030899\n",
      "Elapsed time = 0 hours, 13 minutes, 24.3527450562 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "time1 = time.time()\n",
    "print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 22)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.39133096, -0.27442911, -0.64612275, ..., -0.02209489,\n",
       "         1.34912241, -1.28404224],\n",
       "       [ 1.76750171,  0.5814544 ,  0.55570209, ..., -0.29647955,\n",
       "         1.31140757, -3.0269506 ],\n",
       "       [ 1.33953321,  0.03642526,  0.26932773, ..., -0.57074183,\n",
       "         1.61481857, -1.73673403],\n",
       "       [ 2.4980371 ,  0.22236168,  5.77681351, ..., -2.55784583,\n",
       "         0.7607308 , -0.28638375],\n",
       "       [ 1.62160802, -1.22865927, -0.52635783, ..., -0.98451412,\n",
       "         2.88381124, -3.38303924]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X22 = np.array(data['extracted_features'])\n",
    "print np.shape(X22)\n",
    "X22[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8693459034\n"
     ]
    }
   ],
   "source": [
    "m22 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m22.fit(X22)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tnthdmm020+0940+1046.png\t0.703939190143\n",
      "2\tldlm000+0220+0166.png\t0.672911750932\n",
      "3\tldlm020+0300+0086.png\t0.656170520923\n",
      "4\tnthdlr020+1380+1166.png\t0.653061031107\n",
      "5\twsldlm000+0500+0166.png\t0.598530571757\n",
      "6\twshdmm000+0660+0166.png\t0.598298523198\n",
      "7\tnthdll000+1060+1006.png\t0.58320996648\n",
      "8\thdmm020+0420+0166.png\t0.56711221415\n",
      "9\tnthdlr020+1340+1126.png\t0.564080096198\n",
      "10\twshdll000+1300+0166.png\t0.558592832075\n",
      "11\twshdlr000+1380+0126.png\t0.556089810145\n",
      "12\twsldlm000+1580+0126.png\t0.553821170925\n",
      "13\tntldlm020+0380+0086.png\t0.549241340939\n",
      "14\twsldlm020+1620+1006.png\t0.549118802039\n",
      "15\tnthdmm000+0740+1006.png\t0.539126716373\n",
      "\n",
      "\n",
      "691\tfig01.png\t0.426010137662\n",
      "979\tfig03.png\t0.40839662886\n",
      "981\tfig00.png\t0.408277968147\n",
      "1170\tfig02.png\t0.397979438503\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m22.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on NeuralNetClassifier in module graphlab.toolkits.classifier.neuralnet_classifier object:\n",
      "\n",
      "neuralnet_classifier_v2 = class NeuralNetClassifier(graphlab.toolkits._supervised_learning.Classifier)\n",
      " |  Neural Network is one of the classical models in artificial intelligence and\n",
      " |  machine learning, and has recently achieved great success in computer vision\n",
      " |  tasks such as object recognition.\n",
      " |  \n",
      " |  This model cannot be constructed directly.  Instead, use\n",
      " |  :func:`graphlab.neuralnet_classifier.create` to create an instance of\n",
      " |  this model.\n",
      " |  Additional details on parameter options and code samples are available in\n",
      " |  the documentation for the create function.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  create\n",
      " |  graphlab.deeplearning.NeuralNet\n",
      " |  graphlab.deeplearning.create\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> # Load the data (From an S3 bucket)\n",
      " |  >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |  >>> test_data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/test')\n",
      " |  ...\n",
      " |  >>> # Create a neural network classifier with the MNIST architecture\n",
      " |  >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |  >>> model = graphlab.neuralnet_classifier.create(data, target='label',\n",
      " |  ...                                              network=net)\n",
      " |  ...\n",
      " |  >>> # Classify test data and evaluate the model\n",
      " |  >>> pred = model.classify(test_data)\n",
      " |  >>> results = model.evaluate(test_data)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NeuralNetClassifier\n",
      " |      graphlab.toolkits._supervised_learning.Classifier\n",
      " |      graphlab.toolkits._supervised_learning.SupervisedLearningModel\n",
      " |      graphlab.toolkits._model.Model\n",
      " |      graphlab.toolkits._model.CustomModel\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_proxy)\n",
      " |      __init__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Print a string description of the model, when the model name is entered\n",
      " |      in the terminal.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string description of the model to the ``print`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out: string\n",
      " |          A description of the model.\n",
      " |  \n",
      " |  classify(self, dataset)\n",
      " |      Return a classification for each example in the ``dataset``, using the\n",
      " |      trained neural network model. The output SFrame contains predictions as\n",
      " |      both class labels and probabilities that the predicted class is correct.\n",
      " |      Input dataset size must be the same as for the training of the model,\n",
      " |      except for images which are automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SFrame\n",
      " |          An SFrame with model predictions i.e class labels and scores. Score is the learned\n",
      " |          probability of the input belonging to that class.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      evaluate, predict, predict_topk\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      \n",
      " |      >>> result = m.classify(validation_data)\n",
      " |      >>> result\n",
      " |      +--------+-------+----------------+\n",
      " |      | row_id | class |     score      |\n",
      " |      +--------+-------+----------------+\n",
      " |      |   0    |   4   | 0.995623886585 |\n",
      " |      |   1    |   1   | 0.928708016872 |\n",
      " |      |   2    |   3   | 0.996967732906 |\n",
      " |      |   3    |   1   | 0.998070061207 |\n",
      " |      |   4    |   7   | 0.999219059944 |\n",
      " |      |   5    |   7   | 0.991823732853 |\n",
      " |      |   6    |   9   | 0.993408679962 |\n",
      " |      |   7    |   9   | 0.924675405025 |\n",
      " |      |   8    |   8   | 0.980929374695 |\n",
      " |      |   9    |   8   | 0.99672973156  |\n",
      " |      |  ...   |  ...  |      ...       |\n",
      " |      +--------+-------+----------------+\n",
      " |      [11896 rows x 3 columns]\n",
      " |  \n",
      " |  evaluate(model, *args, **kwargs)\n",
      " |      Evaluate the model by making predictions of target values and comparing\n",
      " |      these to actual values. Input dataset must be the same size as for the\n",
      " |      training of the model, except for images which are automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset in the same format used for training. The columns names and\n",
      " |          types of the dataset must be the same as that used in training.\n",
      " |      \n",
      " |      metric : {'auto', 'accuracy', 'recall@1', 'recall@5', ...}, optional\n",
      " |          To evaluate multiple metrics, supply a list of metric names, e.g.\n",
      " |          ['accuracy', 'recall@1', 'recall@5'].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : dict\n",
      " |          Dictionary from metric name to value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      ...\n",
      " |      >>> eval_ = m.evaluate(validation_data, metric=['accuracy', 'confusion_matrix'])\n",
      " |      {'accuracy': 0.9624793529510498, 'confusion_matrix':\n",
      " |      +--------------+-----------------+-------+\n",
      " |      | target_label | predicted_label | count |\n",
      " |      +--------------+-----------------+-------+\n",
      " |      |      0       |        0        |  1187 |\n",
      " |      |      2       |        0        |   2   |\n",
      " |      |      3       |        0        |   3   |\n",
      " |      |      4       |        0        |   1   |\n",
      " |      |      5       |        0        |   1   |\n",
      " |      |      6       |        0        |   5   |\n",
      " |      |      7       |        0        |   3   |\n",
      " |      |      8       |        0        |   4   |\n",
      " |      |      9       |        0        |   4   |\n",
      " |      |      1       |        1        |  1296 |\n",
      " |      |     ...      |       ...       |  ...  |\n",
      " |      +--------------+-----------------+-------+\n",
      " |      [77 rows x 3 columns]}\n",
      " |      \n",
      " |      See which digit is most misclassified:\n",
      " |      \n",
      " |      >>> cf_mat = eval_['confusion_matrix']\n",
      " |      >>> cf_mat[cf_mat['target_label'] != cf_mat['predicted_label']].groupby(\n",
      " |      ...     'target_label', graphlab.aggregate.SUM('count'))\n",
      " |      +--------------+--------------+\n",
      " |      | target_label | Sum of count |\n",
      " |      +--------------+--------------+\n",
      " |      |      0       |      17      |\n",
      " |      |      3       |      41      |\n",
      " |      |      1       |      29      |\n",
      " |      |      6       |      22      |\n",
      " |      |      2       |      33      |\n",
      " |      |      8       |      92      |\n",
      " |      |      5       |      38      |\n",
      " |      |      4       |      53      |\n",
      " |      |      9       |      46      |\n",
      " |      |      7       |      83      |\n",
      " |      +--------------+--------------+\n",
      " |      [10 rows x 2 columns]\n",
      " |  \n",
      " |  extract_features(self, dataset, layer_id=None)\n",
      " |      Takes an input dataset, propagates each example through the network,\n",
      " |      and returns an SArray of dense feature vectors, each of which is the concatenation\n",
      " |      of all the hidden unit values at layer[layer_id]. These feature vectors\n",
      " |      can be used as input to train another classifier such as a :py:class:`~graphlab.logistic_classifier.LogisticClassifier`,\n",
      " |      an :py:class:`~graphlab.svm_classifier.SVMClassifier`, another\n",
      " |      :py:class:`~graphlab.neuralnet_classifier.NeuralNetClassifier`, or a :py:class:`~graphlab.boosted_trees_classifier.BoostedTreesClassifier`. Input dataset size must be the same as for the training of the model,\n",
      " |      except for images which are automatically resized.\n",
      " |      \n",
      " |      \n",
      " |      We also are releasing a pre-trained model for ImageNet, as described by\n",
      " |      Alex Krizhevsky et. al. It is located at\n",
      " |      http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45 .\n",
      " |      Using it requires 256 x 256 x 3 images.\n",
      " |      Please see Examples and References for more.\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      layer_id : int , optional\n",
      " |          The index of the layer in neuralnet at which the activations are\n",
      " |          taken to be a dense feature vector. Must be a fully-connected layer.\n",
      " |          Default is None, in which case the layer before the connection\n",
      " |          layer to the output is used.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SArray\n",
      " |          An SArray of dtype array.array containing extracted features.\n",
      " |      \n",
      " |      See Also\n",
      " |      ------------\n",
      " |      graphlab.deeplearning.layers\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      - Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"Imagenet\n",
      " |      classification with deep convolutional neural networks.\" Advances in\n",
      " |      neural information processing systems. 2012.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      >>> # Now, let's extract features from the last layer\n",
      " |      >>> data['features'] = m.extract_features(data)\n",
      " |      >>> # Now, let's build a new classifier on top of extracted features\n",
      " |      >>> m = graphlab.classifier.create(data,\n",
      " |      ...                                          features = ['features'],\n",
      " |      ...                                          target='label')\n",
      " |      \n",
      " |      Now, let's see how to load the ImageNet model, and use it for extracting\n",
      " |      features after resizing the data:\n",
      " |      \n",
      " |      >>> imagenet_model = graphlab.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
      " |      >>> data['image'] = graphlab.image_analysis.resize(data['image'], 256, 256, 3)\n",
      " |      >>> data['imagenet_features'] = imagenet_model.extract_features(data)\n",
      " |  \n",
      " |  get(self, field)\n",
      " |      Get the value of a given field. The list of all queryable fields can\n",
      " |      be obtained programmatically using the :func:`~graphlab.neuralnet_classifier.NeuralNetClassifier.list_fields` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      field: string\n",
      " |          The string of the field to be queried.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out :\n",
      " |          Value of queried field\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(data, target='label',\n",
      " |      ...                                          network = net,\n",
      " |      ...                                          metric=['accuracy', 'recall@2'],\n",
      " |      ...                                          max_iterations=1)\n",
      " |      >>> m.list_fields()\n",
      " |      ['batch_size',\n",
      " |       'bias_l2_regularization',\n",
      " |       'device',\n",
      " |       'features',\n",
      " |       'init_random',\n",
      " |       'l2_regularization',\n",
      " |       'learning_rate',\n",
      " |       'learning_rate_alpha',\n",
      " |       'learning_rate_gamma',\n",
      " |       'learning_rate_schedule',\n",
      " |       'learning_rate_start_epoch',\n",
      " |       'learning_rate_step',\n",
      " |       'max_iterations',\n",
      " |       'metric',\n",
      " |       'min_learning_rate',\n",
      " |       'model_checkpoint_interval',\n",
      " |       'model_checkpoint_path',\n",
      " |       'momentum',\n",
      " |       'network',\n",
      " |       'num_examples',\n",
      " |       'num_feature_columns',\n",
      " |       'num_features',\n",
      " |       'num_iterations',\n",
      " |       'random_crop',\n",
      " |       'random_mirror',\n",
      " |       'subtract_mean',\n",
      " |       'target',\n",
      " |       'training_accuracy',\n",
      " |       'training_recall@2',\n",
      " |       'training_time',\n",
      " |       'validation_accuracy',\n",
      " |       'validation_recall@2']\n",
      " |      >>> m.get('num_iterations')\n",
      " |  \n",
      " |  predict(self, dataset, output_type='class')\n",
      " |      Return the model predictions for ``dataset``. Input dataset size must be\n",
      " |      the same as for the training of the model, except for images which are\n",
      " |      automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      output_type : {\"class\"}, optional\n",
      " |          Choose the return type of the prediction. Available output_types are:\n",
      " |      \n",
      " |          - `class`: output the class label\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SArray\n",
      " |          An SArray with model predictions.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      predict_topk, classify, evaluate\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      ...\n",
      " |      >>> pred = m.predict(validation_data)\n",
      " |      >>> pred\n",
      " |      dtype: int\n",
      " |      Rows: 12060\n",
      " |      [4, 7, 6, 1, 4, 7, 1, 8, 6, 0, 6, 2, 7, 5, 1, 7, 1, 1, ... ]\n",
      " |  \n",
      " |  predict_topk(self, dataset, output_type='score', k=3)\n",
      " |      Return top-k predictions for the ``dataset``, using the trained model.\n",
      " |      Predictions are returned as an SFrame with three columns: `row_id`,\n",
      " |      `class`, and `score` or `rank`, depending on the ``output_type``\n",
      " |      parameter. Input dataset size must be the same as for training of the\n",
      " |      model, except for images which are automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      output_type : {'score', 'rank'}, optional\n",
      " |          Choose the return type of the prediction:\n",
      " |      \n",
      " |          - `rank`: outputs rank along with class label.\n",
      " |          - `score`: outputs raw score along with class label. Score is the learned\n",
      " |          probability of the input belonging to that class.\n",
      " |      \n",
      " |      k : int, optional\n",
      " |          Number of classes to return for each input example.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SFrame\n",
      " |          An SFrame with model predictions.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      predict, classify, evaluate\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      ...\n",
      " |      >>> pred = m.predict_topk(validation_data, k=3)\n",
      " |      >>> pred\n",
      " |      +--------+-------+-------------------+\n",
      " |      | row_id | class |       score       |\n",
      " |      +--------+-------+-------------------+\n",
      " |      |   0    |   4   |   0.995623886585  |\n",
      " |      |   0    |   9   |  0.0038311756216  |\n",
      " |      |   0    |   7   | 0.000301006948575 |\n",
      " |      |   1    |   1   |   0.928708016872  |\n",
      " |      |   1    |   3   |  0.0440889261663  |\n",
      " |      |   1    |   2   |  0.0176190119237  |\n",
      " |      |   2    |   3   |   0.996967732906  |\n",
      " |      |   2    |   2   |  0.00151345680933 |\n",
      " |      |   2    |   7   | 0.000637513934635 |\n",
      " |      |   3    |   1   |   0.998070061207  |\n",
      " |      |  ...   |  ...  |        ...        |\n",
      " |      +--------+-------+-------------------+\n",
      " |      [35688 rows x 3 columns]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._supervised_learning.SupervisedLearningModel:\n",
      " |  \n",
      " |  get_current_options(self)\n",
      " |      Return a dictionary with the options used to define and train the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : dict\n",
      " |          Dictionary with options used to define and train the model.\n",
      " |      \n",
      " |      Examples\n",
      " |      -------\n",
      " |      \n",
      " |      >>> options = m.get_current_options()\n",
      " |  \n",
      " |  list_fields(self)\n",
      " |      List the fields stored in the model, including data, model, and\n",
      " |      training options. Each field can be queried with the ``get`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : list\n",
      " |          List of fields queryable with the ``get`` method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> fields =  m.list_fields()\n",
      " |  \n",
      " |  show(self, view=None, model_type='regression')\n",
      " |      show(view=None)\n",
      " |      Visualize with GraphLab Canvas :mod:`~graphlab.canvas`.\n",
      " |      This function starts Canvas if it is not already running.\n",
      " |      If the Model has already been plotted, this function will update the plot.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      view : str, optional\n",
      " |          The name of the Model view to show. Can be one of:\n",
      " |      \n",
      " |          - *Summary*: The summary description of a Model.\n",
      " |          - *Evaluation*: A visual representation of the evaluation results for\n",
      " |            a Model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      view : graphlab.canvas.view.View\n",
      " |          An object representing the GraphLab Canvas view\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canvas\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Suppose 'm' is a Model, we can view it in GraphLab Canvas using:\n",
      " |      \n",
      " |      >>> m.show()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._model.Model:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  name(self)\n",
      " |      Returns the name of the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : str\n",
      " |          The name of the model object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> model_name = m.name()\n",
      " |  \n",
      " |  save(self, location)\n",
      " |      Save the model. The model is saved as a directory which can then be\n",
      " |      loaded using the :py:func:`~graphlab.load_model` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      location : string\n",
      " |          Target destination for the model. Can be a local path or remote URL.\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      graphlab.load_model\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      >>> model.save('my_model_file')\n",
      " |      >>> loaded_model = graphlab.load_model('my_model_file')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from graphlab.toolkits._model.Model:\n",
      " |  \n",
      " |  __proxy__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._model.CustomModel:\n",
      " |  \n",
      " |  summary(self, output=None)\n",
      " |      Print a summary of the model.\n",
      " |      The summary includes a description of training\n",
      " |      data, options, hyper-parameters, and statistics measured during model\n",
      " |      creation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> m.summary()\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      output : string, None\n",
      " |          The type of summary to return.\n",
      " |          None or 'stdout' : prints directly to stdout\n",
      " |          'str' : string of summary\n",
      " |          'dict' : a dict with 'sections' and 'section_titles' ordered lists\n",
      " |                      The entries in the 'sections' list are tuples of the form ('label', 'value')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from graphlab.toolkits._model.CustomModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "time1 = time.time\n",
    "print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 21)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.13311839,  1.74991465, -0.53586638, ..., -4.63365936,\n",
       "         1.16232181, -2.3071599 ],\n",
       "       [ 0.34298587,  2.45043421,  0.31843156, ..., -3.06454062,\n",
       "         0.06621611, -2.48183918],\n",
       "       [-0.66870165,  2.05958056, -0.98619831, ..., -4.17561054,\n",
       "         1.24312103, -2.19206047],\n",
       "       [-1.57564211,  2.51387453, -1.62678885, ..., -2.4753325 ,\n",
       "        -0.29885268, -2.04687071],\n",
       "       [-3.85620332,  6.15582085, -4.85414505, ..., -4.13845158,\n",
       "        -0.13795936,  1.29018736]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X21 = np.array(data['extracted_features'])\n",
    "print np.shape(X21)\n",
    "X21[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.6877818108\n"
     ]
    }
   ],
   "source": [
    "m21 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m21.fit(X21)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tldlm020+0300+0086.png\t0.612971364204\n",
      "2\tnthdmm020+0940+1046.png\t0.606459703844\n",
      "3\tldlm000+0220+0166.png\t0.569214162744\n",
      "4\tnthdlr020+1380+1166.png\t0.544138268275\n",
      "5\twshdlr000+1380+0126.png\t0.465919982239\n",
      "6\twshdmm000+0660+0166.png\t0.465663325207\n",
      "7\thdmm020+1380+1046.png\t0.465116244784\n",
      "8\thdll020+1620+1086.png\t0.452411784979\n",
      "9\thdll020+0300+0086.png\t0.451601639546\n",
      "10\thdlr020+1380+1046.png\t0.451599022895\n",
      "11\thdll020+0820+0086.png\t0.449576931246\n",
      "12\tnthdmm000+0820+1006.png\t0.448086825148\n",
      "13\twshdmm000+1140+0166.png\t0.445078425141\n",
      "14\tnthdlr020+0860+1006.png\t0.443996206774\n",
      "15\twshdll020+0740+0166.png\t0.442248881515\n",
      "\n",
      "\n",
      "646\tfig01.png\t0.307947245958\n",
      "1049\tfig03.png\t0.281181795939\n",
      "1261\tfig02.png\t0.268989787051\n",
      "1361\tfig00.png\t0.264065256583\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m21.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.530540943146\n",
      "Help on NeuralNetClassifier in module graphlab.toolkits.classifier.neuralnet_classifier object:\n",
      "\n",
      "neuralnet_classifier_v2 = class NeuralNetClassifier(graphlab.toolkits._supervised_learning.Classifier)\n",
      " |  Neural Network is one of the classical models in artificial intelligence and\n",
      " |  machine learning, and has recently achieved great success in computer vision\n",
      " |  tasks such as object recognition.\n",
      " |  \n",
      " |  This model cannot be constructed directly.  Instead, use\n",
      " |  :func:`graphlab.neuralnet_classifier.create` to create an instance of\n",
      " |  this model.\n",
      " |  Additional details on parameter options and code samples are available in\n",
      " |  the documentation for the create function.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  create\n",
      " |  graphlab.deeplearning.NeuralNet\n",
      " |  graphlab.deeplearning.create\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> # Load the data (From an S3 bucket)\n",
      " |  >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |  >>> test_data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/test')\n",
      " |  ...\n",
      " |  >>> # Create a neural network classifier with the MNIST architecture\n",
      " |  >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |  >>> model = graphlab.neuralnet_classifier.create(data, target='label',\n",
      " |  ...                                              network=net)\n",
      " |  ...\n",
      " |  >>> # Classify test data and evaluate the model\n",
      " |  >>> pred = model.classify(test_data)\n",
      " |  >>> results = model.evaluate(test_data)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NeuralNetClassifier\n",
      " |      graphlab.toolkits._supervised_learning.Classifier\n",
      " |      graphlab.toolkits._supervised_learning.SupervisedLearningModel\n",
      " |      graphlab.toolkits._model.Model\n",
      " |      graphlab.toolkits._model.CustomModel\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_proxy)\n",
      " |      __init__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Print a string description of the model, when the model name is entered\n",
      " |      in the terminal.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string description of the model to the ``print`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out: string\n",
      " |          A description of the model.\n",
      " |  \n",
      " |  classify(self, dataset)\n",
      " |      Return a classification for each example in the ``dataset``, using the\n",
      " |      trained neural network model. The output SFrame contains predictions as\n",
      " |      both class labels and probabilities that the predicted class is correct.\n",
      " |      Input dataset size must be the same as for the training of the model,\n",
      " |      except for images which are automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SFrame\n",
      " |          An SFrame with model predictions i.e class labels and scores. Score is the learned\n",
      " |          probability of the input belonging to that class.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      evaluate, predict, predict_topk\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      \n",
      " |      >>> result = m.classify(validation_data)\n",
      " |      >>> result\n",
      " |      +--------+-------+----------------+\n",
      " |      | row_id | class |     score      |\n",
      " |      +--------+-------+----------------+\n",
      " |      |   0    |   4   | 0.995623886585 |\n",
      " |      |   1    |   1   | 0.928708016872 |\n",
      " |      |   2    |   3   | 0.996967732906 |\n",
      " |      |   3    |   1   | 0.998070061207 |\n",
      " |      |   4    |   7   | 0.999219059944 |\n",
      " |      |   5    |   7   | 0.991823732853 |\n",
      " |      |   6    |   9   | 0.993408679962 |\n",
      " |      |   7    |   9   | 0.924675405025 |\n",
      " |      |   8    |   8   | 0.980929374695 |\n",
      " |      |   9    |   8   | 0.99672973156  |\n",
      " |      |  ...   |  ...  |      ...       |\n",
      " |      +--------+-------+----------------+\n",
      " |      [11896 rows x 3 columns]\n",
      " |  \n",
      " |  evaluate(model, *args, **kwargs)\n",
      " |      Evaluate the model by making predictions of target values and comparing\n",
      " |      these to actual values. Input dataset must be the same size as for the\n",
      " |      training of the model, except for images which are automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset in the same format used for training. The columns names and\n",
      " |          types of the dataset must be the same as that used in training.\n",
      " |      \n",
      " |      metric : {'auto', 'accuracy', 'recall@1', 'recall@5', ...}, optional\n",
      " |          To evaluate multiple metrics, supply a list of metric names, e.g.\n",
      " |          ['accuracy', 'recall@1', 'recall@5'].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : dict\n",
      " |          Dictionary from metric name to value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      ...\n",
      " |      >>> eval_ = m.evaluate(validation_data, metric=['accuracy', 'confusion_matrix'])\n",
      " |      {'accuracy': 0.9624793529510498, 'confusion_matrix':\n",
      " |      +--------------+-----------------+-------+\n",
      " |      | target_label | predicted_label | count |\n",
      " |      +--------------+-----------------+-------+\n",
      " |      |      0       |        0        |  1187 |\n",
      " |      |      2       |        0        |   2   |\n",
      " |      |      3       |        0        |   3   |\n",
      " |      |      4       |        0        |   1   |\n",
      " |      |      5       |        0        |   1   |\n",
      " |      |      6       |        0        |   5   |\n",
      " |      |      7       |        0        |   3   |\n",
      " |      |      8       |        0        |   4   |\n",
      " |      |      9       |        0        |   4   |\n",
      " |      |      1       |        1        |  1296 |\n",
      " |      |     ...      |       ...       |  ...  |\n",
      " |      +--------------+-----------------+-------+\n",
      " |      [77 rows x 3 columns]}\n",
      " |      \n",
      " |      See which digit is most misclassified:\n",
      " |      \n",
      " |      >>> cf_mat = eval_['confusion_matrix']\n",
      " |      >>> cf_mat[cf_mat['target_label'] != cf_mat['predicted_label']].groupby(\n",
      " |      ...     'target_label', graphlab.aggregate.SUM('count'))\n",
      " |      +--------------+--------------+\n",
      " |      | target_label | Sum of count |\n",
      " |      +--------------+--------------+\n",
      " |      |      0       |      17      |\n",
      " |      |      3       |      41      |\n",
      " |      |      1       |      29      |\n",
      " |      |      6       |      22      |\n",
      " |      |      2       |      33      |\n",
      " |      |      8       |      92      |\n",
      " |      |      5       |      38      |\n",
      " |      |      4       |      53      |\n",
      " |      |      9       |      46      |\n",
      " |      |      7       |      83      |\n",
      " |      +--------------+--------------+\n",
      " |      [10 rows x 2 columns]\n",
      " |  \n",
      " |  extract_features(self, dataset, layer_id=None)\n",
      " |      Takes an input dataset, propagates each example through the network,\n",
      " |      and returns an SArray of dense feature vectors, each of which is the concatenation\n",
      " |      of all the hidden unit values at layer[layer_id]. These feature vectors\n",
      " |      can be used as input to train another classifier such as a :py:class:`~graphlab.logistic_classifier.LogisticClassifier`,\n",
      " |      an :py:class:`~graphlab.svm_classifier.SVMClassifier`, another\n",
      " |      :py:class:`~graphlab.neuralnet_classifier.NeuralNetClassifier`, or a :py:class:`~graphlab.boosted_trees_classifier.BoostedTreesClassifier`. Input dataset size must be the same as for the training of the model,\n",
      " |      except for images which are automatically resized.\n",
      " |      \n",
      " |      \n",
      " |      We also are releasing a pre-trained model for ImageNet, as described by\n",
      " |      Alex Krizhevsky et. al. It is located at\n",
      " |      http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45 .\n",
      " |      Using it requires 256 x 256 x 3 images.\n",
      " |      Please see Examples and References for more.\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      layer_id : int , optional\n",
      " |          The index of the layer in neuralnet at which the activations are\n",
      " |          taken to be a dense feature vector. Must be a fully-connected layer.\n",
      " |          Default is None, in which case the layer before the connection\n",
      " |          layer to the output is used.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SArray\n",
      " |          An SArray of dtype array.array containing extracted features.\n",
      " |      \n",
      " |      See Also\n",
      " |      ------------\n",
      " |      graphlab.deeplearning.layers\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      - Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"Imagenet\n",
      " |      classification with deep convolutional neural networks.\" Advances in\n",
      " |      neural information processing systems. 2012.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      >>> # Now, let's extract features from the last layer\n",
      " |      >>> data['features'] = m.extract_features(data)\n",
      " |      >>> # Now, let's build a new classifier on top of extracted features\n",
      " |      >>> m = graphlab.classifier.create(data,\n",
      " |      ...                                          features = ['features'],\n",
      " |      ...                                          target='label')\n",
      " |      \n",
      " |      Now, let's see how to load the ImageNet model, and use it for extracting\n",
      " |      features after resizing the data:\n",
      " |      \n",
      " |      >>> imagenet_model = graphlab.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
      " |      >>> data['image'] = graphlab.image_analysis.resize(data['image'], 256, 256, 3)\n",
      " |      >>> data['imagenet_features'] = imagenet_model.extract_features(data)\n",
      " |  \n",
      " |  get(self, field)\n",
      " |      Get the value of a given field. The list of all queryable fields can\n",
      " |      be obtained programmatically using the :func:`~graphlab.neuralnet_classifier.NeuralNetClassifier.list_fields` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      field: string\n",
      " |          The string of the field to be queried.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out :\n",
      " |          Value of queried field\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(data, target='label',\n",
      " |      ...                                          network = net,\n",
      " |      ...                                          metric=['accuracy', 'recall@2'],\n",
      " |      ...                                          max_iterations=1)\n",
      " |      >>> m.list_fields()\n",
      " |      ['batch_size',\n",
      " |       'bias_l2_regularization',\n",
      " |       'device',\n",
      " |       'features',\n",
      " |       'init_random',\n",
      " |       'l2_regularization',\n",
      " |       'learning_rate',\n",
      " |       'learning_rate_alpha',\n",
      " |       'learning_rate_gamma',\n",
      " |       'learning_rate_schedule',\n",
      " |       'learning_rate_start_epoch',\n",
      " |       'learning_rate_step',\n",
      " |       'max_iterations',\n",
      " |       'metric',\n",
      " |       'min_learning_rate',\n",
      " |       'model_checkpoint_interval',\n",
      " |       'model_checkpoint_path',\n",
      " |       'momentum',\n",
      " |       'network',\n",
      " |       'num_examples',\n",
      " |       'num_feature_columns',\n",
      " |       'num_features',\n",
      " |       'num_iterations',\n",
      " |       'random_crop',\n",
      " |       'random_mirror',\n",
      " |       'subtract_mean',\n",
      " |       'target',\n",
      " |       'training_accuracy',\n",
      " |       'training_recall@2',\n",
      " |       'training_time',\n",
      " |       'validation_accuracy',\n",
      " |       'validation_recall@2']\n",
      " |      >>> m.get('num_iterations')\n",
      " |  \n",
      " |  predict(self, dataset, output_type='class')\n",
      " |      Return the model predictions for ``dataset``. Input dataset size must be\n",
      " |      the same as for the training of the model, except for images which are\n",
      " |      automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      output_type : {\"class\"}, optional\n",
      " |          Choose the return type of the prediction. Available output_types are:\n",
      " |      \n",
      " |          - `class`: output the class label\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SArray\n",
      " |          An SArray with model predictions.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      predict_topk, classify, evaluate\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      ...\n",
      " |      >>> pred = m.predict(validation_data)\n",
      " |      >>> pred\n",
      " |      dtype: int\n",
      " |      Rows: 12060\n",
      " |      [4, 7, 6, 1, 4, 7, 1, 8, 6, 0, 6, 2, 7, 5, 1, 7, 1, 1, ... ]\n",
      " |  \n",
      " |  predict_topk(self, dataset, output_type='score', k=3)\n",
      " |      Return top-k predictions for the ``dataset``, using the trained model.\n",
      " |      Predictions are returned as an SFrame with three columns: `row_id`,\n",
      " |      `class`, and `score` or `rank`, depending on the ``output_type``\n",
      " |      parameter. Input dataset size must be the same as for training of the\n",
      " |      model, except for images which are automatically resized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataset : SFrame\n",
      " |          Dataset of new observations. Must include columns with the same\n",
      " |          names as the features used for model training, but does not require\n",
      " |          a target column. Additional columns are ignored.\n",
      " |      \n",
      " |      output_type : {'score', 'rank'}, optional\n",
      " |          Choose the return type of the prediction:\n",
      " |      \n",
      " |          - `rank`: outputs rank along with class label.\n",
      " |          - `score`: outputs raw score along with class label. Score is the learned\n",
      " |          probability of the input belonging to that class.\n",
      " |      \n",
      " |      k : int, optional\n",
      " |          Number of classes to return for each input example.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : SFrame\n",
      " |          An SFrame with model predictions.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      predict, classify, evaluate\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train')\n",
      " |      >>> training_data, validation_data = data.random_split(0.8)\n",
      " |      >>> net = graphlab.deeplearning.get_builtin_neuralnet('mnist')\n",
      " |      >>> m = graphlab.neuralnet_classifier.create(training_data,\n",
      " |      ...                                          target='label',\n",
      " |      ...                                          network=net,\n",
      " |      ...                                          max_iterations=3)\n",
      " |      ...\n",
      " |      >>> pred = m.predict_topk(validation_data, k=3)\n",
      " |      >>> pred\n",
      " |      +--------+-------+-------------------+\n",
      " |      | row_id | class |       score       |\n",
      " |      +--------+-------+-------------------+\n",
      " |      |   0    |   4   |   0.995623886585  |\n",
      " |      |   0    |   9   |  0.0038311756216  |\n",
      " |      |   0    |   7   | 0.000301006948575 |\n",
      " |      |   1    |   1   |   0.928708016872  |\n",
      " |      |   1    |   3   |  0.0440889261663  |\n",
      " |      |   1    |   2   |  0.0176190119237  |\n",
      " |      |   2    |   3   |   0.996967732906  |\n",
      " |      |   2    |   2   |  0.00151345680933 |\n",
      " |      |   2    |   7   | 0.000637513934635 |\n",
      " |      |   3    |   1   |   0.998070061207  |\n",
      " |      |  ...   |  ...  |        ...        |\n",
      " |      +--------+-------+-------------------+\n",
      " |      [35688 rows x 3 columns]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._supervised_learning.SupervisedLearningModel:\n",
      " |  \n",
      " |  get_current_options(self)\n",
      " |      Return a dictionary with the options used to define and train the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : dict\n",
      " |          Dictionary with options used to define and train the model.\n",
      " |      \n",
      " |      Examples\n",
      " |      -------\n",
      " |      \n",
      " |      >>> options = m.get_current_options()\n",
      " |  \n",
      " |  list_fields(self)\n",
      " |      List the fields stored in the model, including data, model, and\n",
      " |      training options. Each field can be queried with the ``get`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : list\n",
      " |          List of fields queryable with the ``get`` method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> fields =  m.list_fields()\n",
      " |  \n",
      " |  show(self, view=None, model_type='regression')\n",
      " |      show(view=None)\n",
      " |      Visualize with GraphLab Canvas :mod:`~graphlab.canvas`.\n",
      " |      This function starts Canvas if it is not already running.\n",
      " |      If the Model has already been plotted, this function will update the plot.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      view : str, optional\n",
      " |          The name of the Model view to show. Can be one of:\n",
      " |      \n",
      " |          - *Summary*: The summary description of a Model.\n",
      " |          - *Evaluation*: A visual representation of the evaluation results for\n",
      " |            a Model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      view : graphlab.canvas.view.View\n",
      " |          An object representing the GraphLab Canvas view\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canvas\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Suppose 'm' is a Model, we can view it in GraphLab Canvas using:\n",
      " |      \n",
      " |      >>> m.show()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._model.Model:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  name(self)\n",
      " |      Returns the name of the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : str\n",
      " |          The name of the model object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> model_name = m.name()\n",
      " |  \n",
      " |  save(self, location)\n",
      " |      Save the model. The model is saved as a directory which can then be\n",
      " |      loaded using the :py:func:`~graphlab.load_model` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      location : string\n",
      " |          Target destination for the model. Can be a local path or remote URL.\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      graphlab.load_model\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      >>> model.save('my_model_file')\n",
      " |      >>> loaded_model = graphlab.load_model('my_model_file')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from graphlab.toolkits._model.Model:\n",
      " |  \n",
      " |  __proxy__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from graphlab.toolkits._model.CustomModel:\n",
      " |  \n",
      " |  summary(self, output=None)\n",
      " |      Print a summary of the model.\n",
      " |      The summary includes a description of training\n",
      " |      data, options, hyper-parameters, and statistics measured during model\n",
      " |      creation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> m.summary()\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      output : string, None\n",
      " |          The type of summary to return.\n",
      " |          None or 'stdout' : prints directly to stdout\n",
      " |          'str' : string of summary\n",
      " |          'dict' : a dict with 'sections' and 'section_titles' ordered lists\n",
      " |                      The entries in the 'sections' list are tuples of the form ('label', 'value')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from graphlab.toolkits._model.CustomModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n",
      "795.296192169\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "time1 = time.time()\n",
    "print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 20)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.13311839,  1.74991465,  0.        , ...,  0.        ,\n",
       "         1.16232181,  0.        ],\n",
       "       [ 0.34298587,  2.45043421,  0.31843156, ...,  0.        ,\n",
       "         0.06621611,  0.        ],\n",
       "       [ 0.        ,  2.05958056,  0.        , ...,  0.        ,\n",
       "         1.24312103,  0.        ],\n",
       "       [ 0.        ,  2.51387453,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  6.15582085,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.29018736]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X20 = np.array(data['extracted_features'])\n",
    "print np.shape(X20)\n",
    "X20[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.6528069973\n"
     ]
    }
   ],
   "source": [
    "m20 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m20.fit(X20)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tnthdmm020+0940+1046.png\t0.595912931591\n",
      "2\tldlm000+0220+0166.png\t0.575106881181\n",
      "3\tldlm020+0300+0086.png\t0.565322775139\n",
      "4\tnthdlr020+1380+1166.png\t0.559275424649\n",
      "5\twshdmm000+0660+0166.png\t0.508471408203\n",
      "6\twshdlr000+1380+0126.png\t0.491321908729\n",
      "7\thdmm020+1380+1046.png\t0.487924836722\n",
      "8\twshdlr000+0180+0166.png\t0.483795201816\n",
      "9\thdmm020+0940+0166.png\t0.480773542299\n",
      "10\twshdmm000+1140+0166.png\t0.470660062073\n",
      "11\thdmm020+0420+0166.png\t0.468624072668\n",
      "12\thdll020+1620+1086.png\t0.467303049218\n",
      "13\twshdll020+0740+0166.png\t0.460842271418\n",
      "14\thdlr020+1380+1046.png\t0.45796698223\n",
      "15\tnthdll020+1180+1126.png\t0.457491335966\n",
      "\n",
      "\n",
      "731\tfig03.png\t0.306764515088\n",
      "856\tfig01.png\t0.298442299622\n",
      "1196\tfig00.png\t0.279005151003\n",
      "1223\tfig02.png\t0.277403725868\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m20.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "time1 = time.time()\n",
    "print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 19)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X19 = np.array(data['extracted_features'])\n",
    "print np.shape(X19)\n",
    "X19[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m19 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m19.fit(X19)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\twshdlr020+0940+0086.png\t0.738360641833\n",
      "2\tntldlm020+0380+0086.png\t0.661715994829\n",
      "3\thdll000+0580+0166.png\t0.657598281129\n",
      "4\thdll020+0420+0166.png\t0.645117571722\n",
      "5\tldlm000+0220+0166.png\t0.64409745037\n",
      "6\twshdmm020+0540+0126.png\t0.640095443936\n",
      "7\thdlr020+0940+0126.png\t0.630928611102\n",
      "8\tnthdmm000+0780+1006.png\t0.627408515018\n",
      "9\tnthdmm020+0940+1046.png\t0.614622902864\n",
      "10\twshdlr000+1020+0126.png\t0.611898833369\n",
      "11\tnthdmm000+0180+1006.png\t0.609212665349\n",
      "12\tnthdmm020+0660+0086.png\t0.604429025503\n",
      "13\tnthdlr020+1380+1166.png\t0.599252722627\n",
      "14\tntldlm000+1020+0166.png\t0.598826325631\n",
      "15\twshdlr020+0820+0046.png\t0.597980794482\n",
      "\n",
      "\n",
      "551\tfig03.png\t0.417132264575\n",
      "1065\tfig00.png\t0.383883846599\n",
      "1437\tfig02.png\t0.365714986349\n",
      "1771\tfig01.png\t0.345910483029\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m19.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try with raw pixels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sux. Will suggests mean image subtraction as a possible issue.\n",
    "\n",
    "*A good suggestion, but Dato says not needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.4639201164\n"
     ]
    }
   ],
   "source": [
    "model = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "model.fit(Xraw)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tfig03.png\t0.642686526162\n",
      "2\tfig01.png\t0.592166616477\n",
      "3\tfig00.png\t0.584799065274\n",
      "4\thdll020+1220+1006.png\t0.571184821503\n",
      "5\thdll020+1260+1006.png\t0.57079325063\n",
      "6\tnthdll020+1300+1166.png\t0.568242523467\n",
      "7\thdll020+1460+1086.png\t0.560627337362\n",
      "8\tnthdll020+0780+1006.png\t0.555812389857\n",
      "9\tnthdll020+1100+1086.png\t0.554378542823\n",
      "10\tnthdll000+0980+1006.png\t0.548041106224\n",
      "11\tnthdll020+0820+1006.png\t0.545517864877\n",
      "12\thdll020+1300+1006.png\t0.544984478374\n",
      "13\tnthdll020+1260+1126.png\t0.54364769456\n",
      "14\tnthdll000+0900+1006.png\t0.542881674059\n",
      "15\thdll020+1500+1086.png\t0.541418920174\n",
      "\n",
      "\n",
      "1\tfig03.png\t0.642686526162\n",
      "2\tfig01.png\t0.592166616477\n",
      "3\tfig00.png\t0.584799065274\n",
      "63\tfig02.png\t0.489604189264\n"
     ]
    }
   ],
   "source": [
    "anom_scores = model.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
