{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are numerous decisions for me to make (very quickly):\n",
    "\n",
    "* How to present results of classifier so that they do not bias viewer's interpretation of greyscale images. (If I use color, viewer is likely as not to be tricked by the colors into believing there are differences where labeled, even if not merited by the underlying data.\n",
    "* Should I attempt iForest anomaly detection on images? **Yes!**\n",
    "  * Advantage: (there exists code) [there exists code](http://stackoverflow.com/questions/30080491/isolation-forest-algorithm-in-python \"code provided by user on stackoverflow\")\n",
    "  * Disadvantages: author claims that it is slow, it is not well tested. *Seems to work.*\n",
    "  * That same reference points to sklearn github pull-request for [a model of increasing maturity](https://github.com/scikit-learn/scikit-learn/pull/4163 \"not yet ready for sklearn\"), but not yet fully working and not super-well-tested. Another month or two?\n",
    "  * To impliment iForest, would need to extract feature weights from trained model. Can I do this with Dato's imagenet classifier? **Yes! However, there are devils in the details to be worked out.**\n",
    "  \n",
    "### Regarding presentation:\n",
    "  \n",
    "  * For minimum viable product:\n",
    "    * Use [Flask-Uploads](https://pythonhosted.org/Flask-Uploads/) to allow a user to upload a directory filled with images.\n",
    "    * Apply iForest and rank by anomaly score\n",
    "    * Present a table with columns [256 x 256 images, file names, anomaly score], ranked by anomaly score.\n",
    "\n",
    "  * If can't work out NN features, do minimum minimum viable product using iForest on pixel values.\n",
    "  \n",
    "### Things to implement:\n",
    "\n",
    "  * Make sure that can work with color photos as well as grayscale. Should app to a detect on each file and convert to that which is most consistent with others in directory?\n",
    "  * Would be great to add audio, converting to FFT, clipping or repeating to a nominal length.\n",
    "  * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from code import iForest as isof\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try iForest using real image data (raw pixels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngCt: 2064\n",
      "/home/wilber/work/Galvanize/gcp-data/iForest/loonie\n",
      "0\thdll020+0300+0126.png\t<type 'numpy.ndarray'>\n",
      "100\twshdll020+0740+0086.png\t<type 'numpy.ndarray'>\n",
      "200\tldlm020+0620+0086.png\t<type 'numpy.ndarray'>\n",
      "300\thdmm000+0460+0166.png\t<type 'numpy.ndarray'>\n",
      "400\tnthdmm020+0340+0166.png\t<type 'numpy.ndarray'>\n",
      "500\twshdll000+1500+0126.png\t<type 'numpy.ndarray'>\n",
      "600\thdll020+0220+0086.png\t<type 'numpy.ndarray'>\n",
      "700\twshdmm020+1180+0166.png\t<type 'numpy.ndarray'>\n",
      "800\tntldlm020+0860+0166.png\t<type 'numpy.ndarray'>\n",
      "900\tldlm020+0780+0166.png\t<type 'numpy.ndarray'>\n",
      "1000\tldlm020+1620+1086.png\t<type 'numpy.ndarray'>\n",
      "1100\tldlm000+1060+0166.png\t<type 'numpy.ndarray'>\n",
      "1200\thdlr020+0300+0166.png\t<type 'numpy.ndarray'>\n",
      "1300\tnthdlr020+0500+0166.png\t<type 'numpy.ndarray'>\n",
      "1400\tntldlm020+1140+1046.png\t<type 'numpy.ndarray'>\n",
      "1500\twshdlr000+0540+0166.png\t<type 'numpy.ndarray'>\n",
      "1600\thdll020+0460+0126.png\t<type 'numpy.ndarray'>\n",
      "1700\twsldlm000+1460+0126.png\t<type 'numpy.ndarray'>\n",
      "1800\thdlr020+1300+1006.png\t<type 'numpy.ndarray'>\n",
      "1900\tntldlm000+0620+0166.png\t<type 'numpy.ndarray'>\n",
      "2000\tldlm000+1100+0166.png\t<type 'numpy.ndarray'>\n",
      "(2064, 10000)\n",
      "[[  56.   75.   84.   79.   76.   74.   74.   80.   76.   77.   78.   69.\n",
      "    79.   76.   89.   74.   78.   77.   69.   99.]\n",
      " [  40.   40.   37.   35.   34.   35.   37.   38.   36.   34.   35.   37.\n",
      "    37.   37.   38.   38.   40.   42.   44.   49.]\n",
      " [  90.  120.  122.   84.   66.   70.   83.   98.   98.   95.   98.   92.\n",
      "    97.   97.   93.   94.   94.   87.   70.   59.]\n",
      " [  56.   55.   60.   62.   60.   56.   53.   54.   55.   56.   56.   56.\n",
      "    55.   55.   56.   58.   60.   61.   62.   64.]\n",
      " [  52.   55.   55.   51.   48.   46.   52.   58.   58.   55.   57.   63.\n",
      "    56.   50.   49.   49.   50.   51.   53.   51.]\n",
      " [  76.   82.   84.   87.  100.   99.   86.   65.   63.   73.   67.   65.\n",
      "    74.   89.   84.   70.   76.   86.   72.   72.]\n",
      " [  46.   45.   45.   45.   44.   44.   44.   43.   45.   44.   44.   46.\n",
      "    46.   43.   42.   43.   44.   44.   44.   45.]\n",
      " [  25.   33.   37.   56.   73.   98.  107.  114.  109.  106.   95.   83.\n",
      "    93.  108.  109.   94.   66.   80.  108.  116.]\n",
      " [  72.   70.   64.   63.   66.   68.   68.   70.   77.   85.   83.   77.\n",
      "    82.   87.   84.   73.   62.   56.   75.   94.]\n",
      " [  71.   73.   75.   82.   96.  104.   96.   82.   81.   74.   77.   93.\n",
      "   102.   99.   96.   97.   97.   95.  103.  101.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hdll020+0300+0126.png',\n",
       " 'wsldlm000+0820+0166.png',\n",
       " 'nthdmm000+1020+1006.png',\n",
       " 'ntldlm000+1540+0166.png',\n",
       " 'ntldlm000+1020+0166.png',\n",
       " 'nthdlr020+0260+0046.png',\n",
       " 'ntldlm020+1020+1086.png',\n",
       " 'nthdll020+1340+1086.png',\n",
       " 'wshdll020+0500+0086.png',\n",
       " 'wshdlr000+1380+0126.png']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "#WORK_DIR = '/home/wilber/work/Galvanize/gcp-data/iForest/'\n",
    "WORK_DIR = '/home/wilber/work/Galvanize/gcp-data/iForest/loonie'\n",
    "pngCt = len(glob.glob1(WORK_DIR,\"*.png\"))\n",
    "print \"pngCt: {0}\".format(pngCt)\n",
    "%cd /home/wilber/work/Galvanize/gcp-data/iForest/loonie\n",
    "Xnames = [\"\"]*pngCt\n",
    "\n",
    "grayscale = True\n",
    "if grayscale:\n",
    "    Xraw = np.full((pngCt, 10000), np.nan)\n",
    "else:\n",
    "    Xraw = np.full((pngCt, 30000), np.nan)\n",
    "\n",
    "for i, file in enumerate(os.listdir(WORK_DIR)):\n",
    "    if grayscale:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(file)\n",
    "    if i % 100 == 0:\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, file, type(img))\n",
    "    Xraw[i,:] = img.flatten()\n",
    "    Xnames[i] = file\n",
    "print Xraw.shape\n",
    "print Xraw[:10, :20]\n",
    "Xnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/wilber/work/Galvanize/gcp-data/iForest/loonie'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level features from Dato's ImageNet classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This non-commercial license of GraphLab Create is assigned to wilber@ssl.berkeley.eduand will expire on September 15, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-15433 - Server binary: /home/wilber/work/Galvanize/gcp/dato-env/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1442878614.log\n",
      "[INFO] GraphLab Server Version: 1.5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "WORKING_DIR = '/home/wilber/work/Galvanize/gcp-data/iForest/loonie'\n",
    "data = gl.image_analysis.load_images(WORKING_DIR, \\\n",
    "                                     random_order=True)\n",
    "data['image'] = gl.image_analysis.resize(data['image'], 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nthdlr020+1260+1126.png',\n",
       " 'hdlr020+1620+1006.png',\n",
       " 'nthdll000+1580+1006.png',\n",
       " 'nthdll020+1340+1046.png',\n",
       " 'nthdll020+0820+0166.png',\n",
       " 'wshdmm000+0260+0166.png',\n",
       " 'nthdmm020+1300+1086.png',\n",
       " 'nthdll020+1420+1126.png',\n",
       " 'wshdmm000+1380+0126.png',\n",
       " 'hdll000+0580+0166.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = data['path']\n",
    "names = map(lambda x: x.split('/')[-1], names)\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This non-commercial license of GraphLab Create is assigned to wilber@ssl.berkeley.eduand will expire on September 15, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-12514 - Server binary: /usr/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1442875412.log\n",
      "[INFO] GraphLab Server Version: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "# Import data from MNIST\n",
    "#data = gl.SFrame('http://s3.amazonaws.com/dato-datasets/mnist/sframe/train6k')\n",
    "\n",
    "# Create a DeepFeatureExtractorObject\n",
    "\n",
    "start = time.time()\n",
    "extractor = gl.feature_engineering.DeepFeatureExtractor(feature = 'image')\n",
    "print help(extractor)\n",
    "# Fit the encoder for a given dataset.\n",
    "time1 = time.time()\n",
    "print \"\\n\\n\", time1 - start\n",
    "extractor = extractor.fit(data)\n",
    "time2 = time.time()\n",
    "print \"\\n\\n\", time2 - time1\n",
    "\n",
    "# Return the model used for the deep feature extraction.\n",
    "extracted_model = extractor['model']\n",
    "time3 = time.time()\n",
    "print \"\\n\\n\", time3 - time2\n",
    "\n",
    "# Extract features.\n",
    "features_sf = extractor.transform(data)\n",
    "features_sf.head()\n",
    "time4 = time.time()\n",
    "print \"\\n\\n\", time4 - time3, \", total time: \", time4 - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature = features_sf.head['deep_features_image']\n",
    "features_sf.num_rows(), features_sf.num_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class               : NeuralNetClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Examples            : 1281166\n",
       "Features            : 1\n",
       "Target column       : label\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Training accuracy   : 0.625\n",
       "Validation accuracy : None\n",
       "Training recall@5   : 0.8512\n",
       "Validation recall@5 : None\n",
       "Training time (sec) : 288884.0298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Class               : NeuralNetClassifier\n",
      "\n",
      "Schema\n",
      "------\n",
      "Examples            : 1281166\n",
      "Features            : 1\n",
      "Target column       : label\n",
      "\n",
      "Training Summary\n",
      "----------------\n",
      "Training accuracy   : 0.625\n",
      "Validation accuracy : None\n",
      "Training recall@5   : 0.8512\n",
      "Validation recall@5 : None\n",
      "Training time (sec) : 288884.0298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opts_dict = extractor.get_current_options()\n",
    "for key, value in opts_dict.iteritems():\n",
    "    print key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class               : DeepFeatureExtractor\\n\\nModel fields\\n------------\\nFeature(s)          : image\\nOutput Column Name  : deep_features_image\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['path', 'image', 'deep_features_image']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sf.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 4096)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(features_sf['deep_features_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(features_sf['deep_features_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.72930121,  0.        , ...,  0.        ,\n",
       "         0.94428813,  0.        ],\n",
       "       [ 0.        ,  1.59159303,  0.        , ...,  0.        ,\n",
       "         0.6683253 ,  0.60917962],\n",
       "       [ 1.48337448,  0.        ,  0.65555978, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  2.86736774,  0.        , ...,  0.        ,\n",
       "         1.75487328,  0.        ],\n",
       "       [ 1.57783175,  1.64519286,  0.        , ...,  0.        ,\n",
       "         1.5495981 ,  0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369.748157024\n"
     ]
    }
   ],
   "source": [
    "model = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "model.fit(X)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\twsldlm000+1340+0126.png\t0.615487381279\n",
      "2\tnthdll000+0820+0166.png\t0.590250183857\n",
      "3\thdlr020+0980+0166.png\t0.566325593441\n",
      "4\tnthdlr020+1100+1046.png\t0.549250004206\n",
      "5\thdmm020+1020+0166.png\t0.488050215793\n",
      "6\tldlm020+0300+0166.png\t0.474663087353\n",
      "7\twshdmm020+0900+0086.png\t0.459938195728\n",
      "8\tnthdll020+1180+1126.png\t0.455982553333\n",
      "9\twshdll020+0420+0086.png\t0.452169702796\n",
      "10\thdmm020+0340+0126.png\t0.451372111184\n",
      "11\tnthdmm020+0820+1006.png\t0.448498633964\n",
      "12\twshdmm020+0620+0126.png\t0.446066758839\n",
      "13\thdlr020+0540+0046.png\t0.441880783274\n",
      "14\tntldlm000+0300+1006.png\t0.440740666117\n",
      "15\thdll000+0460+0166.png\t0.440144821711\n",
      "\n",
      "\n",
      "478\tfig01.png\t0.322530355659\n",
      "737\tfig03.png\t0.301604729085\n",
      "1165\tfig00.png\t0.275853525065\n",
      "1850\tfig02.png\t0.234054963318\n"
     ]
    }
   ],
   "source": [
    "anom_scores = model.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different layers from pre-trained model:\n",
    "\n",
    "#### Layer 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45/dir_archive.ini to /var/tmp/graphlab-wilber/15433/000000.ini\n",
      "PROGRESS: Downloading http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45/objects.bin to /var/tmp/graphlab-wilber/15433/000001.bin\n",
      "705.815214157\n",
      "807.152285814\n",
      "Elapsed time = 0 hours, 25 minutes, 12.9680931568 seconds\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "start = time.time()\n",
    "pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "time1 = time.time()\n",
    "pretrained_model = gl.load_model('/home/wilber/work/Galvanize/gcp/DatoImageNetIter45.bin')\n",
    "print \"dt1: \", time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 22)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pretrained_model.save('/home/wilber/work/Galvanize/gcp/DatoImageNetIter45.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.50253224, -1.25021994, -1.01370823, ..., -1.11672926,\n",
       "         2.31823492, -1.5534209 ],\n",
       "       [ 1.77320004, -1.1280663 , -0.63177204, ...,  0.47384962,\n",
       "         2.69098949, -3.60191417],\n",
       "       [ 2.16725302, -0.25370082,  2.50009012, ...,  0.80002779,\n",
       "         1.53945363, -3.46016431],\n",
       "       [ 1.19407737,  0.69893199, -0.22904766, ..., -1.28837085,\n",
       "         1.00509715, -0.897053  ],\n",
       "       [ 1.75302529,  1.67573178, -0.00981579, ..., -0.81604373,\n",
       "         1.33047044, -1.6480968 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X22 = np.array(data['extracted_features'])\n",
    "print np.shape(X22)\n",
    "X22[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering iForest.fit() ...\n",
      "\n",
      "9.99571299553\n"
     ]
    }
   ],
   "source": [
    "m22 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m22.fit(X22)\n",
    "end = time.time()\n",
    "print \"elapsed time: {0}s.\".format(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tfig03.png\t0.734537036602\n",
      "2\tfig00.png\t0.693802240618\n",
      "3\tfig01.png\t0.67009517741\n",
      "4\tfig02.png\t0.636144819234\n",
      "5\thdmm000+1700+0166.png\t0.596015265989\n",
      "6\thdlr020+1380+1006.png\t0.580211618972\n",
      "7\tnthdlr020+0460+0086.png\t0.566919199764\n",
      "8\thdlr020+1340+1046.png\t0.563505802689\n",
      "9\thdll020+1500+1086.png\t0.559962149965\n",
      "10\tntldlm000+0180+1006.png\t0.550150395502\n",
      "11\thdlr020+1340+1006.png\t0.549774212744\n",
      "12\twsldlm000+0900+0166.png\t0.548775950881\n",
      "13\tnthdlr000+1500+1006.png\t0.546197986807\n",
      "14\twsldlm000+1220+0166.png\t0.540605083294\n",
      "15\twsldlm000+1220+0126.png\t0.540116587238\n",
      "\n",
      "\n",
      "1\tfig03.png\t0.734537036602\n",
      "2\tfig00.png\t0.693802240618\n",
      "3\tfig01.png\t0.67009517741\n",
      "4\tfig02.png\t0.636144819234\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m22.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690.17795682\n",
      "Elapsed time = 0 hours, 13 minutes, 8.29797792435 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "#time1 = time.time()\n",
    "#print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 21)\n",
    "totsecs = time.time() - start\n",
    "print totsecs\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.72930121,  0.        , ...,  0.        ,\n",
       "         0.94428813,  0.        ],\n",
       "       [ 0.        ,  1.59159303,  0.        , ...,  0.        ,\n",
       "         0.6683253 ,  0.60917962],\n",
       "       [ 1.48337448,  0.        ,  0.65555978, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  2.86736774,  0.        , ...,  0.        ,\n",
       "         1.75487328,  0.        ],\n",
       "       [ 1.57783175,  1.64519286,  0.        , ...,  0.        ,\n",
       "         1.5495981 ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X21 = np.array(data['extracted_features'])\n",
    "print np.shape(X21)\n",
    "X21[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering iForest.fit() ...\n",
      "\n",
      "elapsed time: 52.0787329674s.\n"
     ]
    }
   ],
   "source": [
    "m21 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m21.fit(X21)\n",
    "end = time.time()\n",
    "print \"elapsed time: {0}s.\".format(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tfig01.png\t0.643959719912\n",
      "2\tfig03.png\t0.631997253255\n",
      "3\tfig00.png\t0.595435446863\n",
      "4\tfig02.png\t0.532603714266\n",
      "5\thdmm000+1700+0166.png\t0.488955551861\n",
      "6\thdll020+1460+1086.png\t0.486480819583\n",
      "7\thdmm020+1540+1086.png\t0.48042025209\n",
      "8\twshdlr020+0180+0126.png\t0.462428910643\n",
      "9\thdll020+1420+1086.png\t0.457481063087\n",
      "10\twshdmm020+1740+1006.png\t0.456926670075\n",
      "11\tnthdlr020+0460+0086.png\t0.454278094795\n",
      "12\tntldlm000+0180+1006.png\t0.448086825148\n",
      "13\tntldlm000+0220+1006.png\t0.445557574545\n",
      "14\thdlr020+1340+1006.png\t0.439459032252\n",
      "15\tnthdlr000+0340+1006.png\t0.437586534955\n",
      "\n",
      "\n",
      "1\tfig01.png\t0.643959719912\n",
      "2\tfig03.png\t0.631997253255\n",
      "3\tfig00.png\t0.595435446863\n",
      "4\tfig02.png\t0.532603714266\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m21.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4243.41244578\n",
      "Elapsed time = 0 hours, 13 minutes, 14.2290129662 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "# time1 = time.time()\n",
    "# print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 20)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.72930121,  0.        , ...,  0.        ,\n",
       "         0.94428813,  0.        ],\n",
       "       [ 0.        ,  1.59159303,  0.        , ...,  0.        ,\n",
       "         0.6683253 ,  0.60917962],\n",
       "       [ 1.48337448,  0.        ,  0.65555978, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  2.86736774,  0.        , ...,  0.        ,\n",
       "         1.75487328,  0.        ],\n",
       "       [ 1.57783175,  1.64519286,  0.        , ...,  0.        ,\n",
       "         1.5495981 ,  0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X20 = np.array(data['extracted_features'])\n",
    "print np.shape(X20)\n",
    "X20[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering iForest.fit() ...\n",
      "\n",
      "elapsed time: 48.0057470798s.\n"
     ]
    }
   ],
   "source": [
    "m20 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m20.fit(X20)\n",
    "end = time.time()\n",
    "print \"elapsed time: {0}s.\".format(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tfig03.png\t0.590907078032\n",
      "2\tfig01.png\t0.583476048129\n",
      "3\tfig00.png\t0.575494741165\n",
      "4\tfig02.png\t0.542881674059\n",
      "5\thdmm000+1700+0166.png\t0.495458899922\n",
      "6\thdll020+1460+1086.png\t0.477883100839\n",
      "7\twshdlr020+0180+0126.png\t0.477283511358\n",
      "8\thdll020+1420+1086.png\t0.471341710934\n",
      "9\tntldlm000+1020+1006.png\t0.46691845264\n",
      "10\thdlr020+1340+1006.png\t0.46166223562\n",
      "11\tnthdll020+1020+1046.png\t0.459579220657\n",
      "12\thdll000+1260+0166.png\t0.458959097771\n",
      "13\tntldlm000+0180+1006.png\t0.455783268035\n",
      "14\tnthdmm020+1380+1126.png\t0.454901907388\n",
      "15\tldlm000+1060+0166.png\t0.453445736703\n",
      "\n",
      "\n",
      "1\tfig03.png\t0.590907078032\n",
      "2\tfig01.png\t0.583476048129\n",
      "3\tfig00.png\t0.575494741165\n",
      "4\tfig02.png\t0.542881674059\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m20.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336.73123693\n",
      "Elapsed time = 0 hours, 13 minutes, 12.6306271553 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# pretrained_model = gl.load_model('http://s3.amazonaws.com/dato-datasets/deeplearning/imagenet_model_iter45')\n",
    "# time1 = time.time()\n",
    "# print time1 - start\n",
    "data['extracted_features'] = pretrained_model.extract_features(data, 19)\n",
    "print time.time() - time1\n",
    "totsecs = time.time() - start\n",
    "hours = int(totsecs/3600)\n",
    "mins = int((totsecs - 3600.*hours)/60)\n",
    "secs = totsecs - 3600.*hours - 60.*mins\n",
    "print \"Elapsed time = {0} hours, {1} minutes, {2} seconds\".format(hours, mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.09079742,  3.72930121, -2.77852869, ..., -4.05487823,\n",
       "         0.94428813, -0.31786889],\n",
       "       [-0.76935959,  1.59159303, -3.82672143, ..., -3.59154534,\n",
       "         0.6683253 ,  0.60917962],\n",
       "       [ 1.48337448, -0.64070177,  0.65555978, ..., -0.35795367,\n",
       "        -0.59973013, -1.34989905],\n",
       "       [-0.27250659,  2.86736774, -0.91383731, ..., -4.791646  ,\n",
       "         1.75487328, -2.50466108],\n",
       "       [ 1.57783175,  1.64519286, -0.28011394, ..., -3.5872457 ,\n",
       "         1.5495981 , -2.22699523]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X19 = np.array(data['extracted_features'])\n",
    "print np.shape(X19)\n",
    "X19[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering iForest.fit() ...\n",
      "\n",
      "elapsed time: 27.300606966s.\n"
     ]
    }
   ],
   "source": [
    "m19 = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "m19.fit(X19)\n",
    "end = time.time()\n",
    "print \"elapsed time: {0}s.\".format(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tnthdll000+0900+1006.png\t0.722790433726\n",
      "2\tnthdlr000+1500+1006.png\t0.673196322709\n",
      "3\twshdll000+0860+0166.png\t0.66657059519\n",
      "4\tnthdlr020+1460+1006.png\t0.651122223423\n",
      "5\tnthdll020+1460+1006.png\t0.648013855295\n",
      "6\tnthdlr000+1540+1006.png\t0.640718432395\n",
      "7\twshdll020+0420+0046.png\t0.634636544086\n",
      "8\tnthdll000+0940+1006.png\t0.632354279033\n",
      "9\tfig02.png\t0.630918772611\n",
      "10\tnthdll020+1420+1006.png\t0.628112758187\n",
      "11\tfig00.png\t0.628013312611\n",
      "12\thdll020+0460+0166.png\t0.607640818237\n",
      "13\tnthdlr020+1340+1206.png\t0.604512939923\n",
      "14\twshdll020+0500+0086.png\t0.601905178846\n",
      "15\tnthdll020+0780+1006.png\t0.601754753757\n",
      "\n",
      "\n",
      "9\tfig02.png\t0.630918772611\n",
      "11\tfig00.png\t0.628013312611\n",
      "17\tfig03.png\t0.597391174453\n",
      "32\tfig01.png\t0.571525568133\n"
     ]
    }
   ],
   "source": [
    "anom_scores = m19.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have gone too far!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try with raw pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering iForest.fit() ...\n",
      "\n",
      "63.1782519817\n"
     ]
    }
   ],
   "source": [
    "model = isof.iForest(n_estimators=200)\n",
    "start = time.time()\n",
    "model.fit(Xraw)\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tfig03.png\t0.616293966178\n",
      "2\tfig01.png\t0.57686392225\n",
      "3\tnthdll000+0900+1006.png\t0.573929882553\n",
      "4\thdll020+1420+1086.png\t0.553295278689\n",
      "5\tnthdll020+0820+1006.png\t0.553048603554\n",
      "6\tfig00.png\t0.551870372783\n",
      "7\thdll020+1460+1086.png\t0.551777778897\n",
      "8\thdll020+1220+1006.png\t0.548237328637\n",
      "9\tnthdll020+1260+1126.png\t0.547619981709\n",
      "10\thdll020+1260+1006.png\t0.546107621288\n",
      "11\tnthdll000+1020+1006.png\t0.54555213689\n",
      "12\tnthdll020+1260+1166.png\t0.545324321227\n",
      "13\tnthdll000+0940+1006.png\t0.530078808273\n",
      "14\tnthdll020+1140+1086.png\t0.529312284063\n",
      "15\tnthdll020+1420+1046.png\t0.52612597045\n",
      "\n",
      "\n",
      "1\tfig03.png\t0.616293966178\n",
      "2\tfig01.png\t0.57686392225\n",
      "6\tfig00.png\t0.551870372783\n",
      "72\tfig02.png\t0.484954116883\n"
     ]
    }
   ],
   "source": [
    "anom_scores = model.anomaly_score_\n",
    "sort_indices = np.argsort(anom_scores)\n",
    "\n",
    "for i in range(1,16):\n",
    "    ind = sort_indices[-i]\n",
    "    print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])\n",
    "\n",
    "print \"\\n\"\n",
    "for i in range(1, 2000):\n",
    "    ind = sort_indices[-i]\n",
    "    if names[ind].startswith('fig'):\n",
    "        print \"{0}\\t{1}\\t{2}\".format(i, names[ind], anom_scores[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
